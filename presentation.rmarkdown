---
title: 'Reproducible Research with <img style="vertical-align:middle; height:35px; width: 35px; border: none;
  background: none;" src="assets/images/Rlogo.png"> and <img style="vertical-align:middle; height:35px; width: 140px;" src="assets/images/quarto-logo-trademark.svg">: Workflows for data, projects and publications'
subtitle: 'Landscape 2024 masterclass'
format:
  revealjs:
    theme: [default, clean.scss]
    embed-resources: true
    pdf-max-pages-per-slide: 1
    menu:
      side: left
    slide-number: true
    date-format: long
    cap-location: bottom
    preview-links: true
author:
  - name: Ben Black
    orcid: 0000-0002-8113-2114
    email: bblack@ethz.ch
    affiliations:
      - ref: PLUS
  - name: Manuel Kurmann
    email: mankurma@student.ethz.ch
    affiliations:
      - ref: PLUS
  - name: Nivedita Harisena
    email: nharisena@ethz.ch
    affiliations:
      - ref: PLUS
  - name: Maarten Van Strien
    email: vanstrien@ethz.ch
    affiliations:
      - ref: PLUS
affiliations:
  - id: PLUS
    name: "Planning of Landscape and Urban Systems (PLUS), ETH Zurich"
date: last-modified
execute:
  eval: false
---



# Schedule

::: incremental
-   Introduction (15 mins)

-   Research projects with R (30 mins)

-   Comfort break (10 mins)

-   3 workflows for Reproducibility (20 mins)

-   Quarto (20 mins)

-   Comfort break (10 mins)

-   Exercise time (45 mins)

-   Discussion + feedback (30 mins)
:::

# Introduction



---
execute:
  echo: true
  eval: false
  error: false
---


<!-- Web content -->

::: {.content-hidden when-format="revealjs"}
## About us

We are four researchers from the research group [Planning of Landscape
and Urban Systems (PLUS)](https://plus.ethz.ch/) at [ETH
Zürich](https://ethz.ch/en.html). Click on the social icons below our
pictures to find out more about our individual research or get in touch
with us.

::: {.grid style="display: flex; text-align: center;"}
::: g-col-6
![](assets/images/Ben.jpg){.picture .lightbox}

### Ben Black

*Doctoral Researcher*

[{{< iconify fa6-solid house-chimney-user size=xl >}}](https://blenback.github.io/){.iconify-icon}
[{{< iconify fa6-solid envelope size=xl >}}](mailto:bblack@ethz.ch){.iconify-icon}
[{{< iconify fa6-brands linkedin size=xl >}}](https://www.linkedin.com/in/ben-black-9889a1150/){.iconify-icon}
[{{< iconify fa6-brands github size=xl >}}](https://github.com/blenback/){.iconify-icon}
[{{< iconify fa6-brands researchgate size=xl >}}](https://www.researchgate.net/profile/Benjamin-Black-5/){.iconify-icon}
:::

::: g-col-6
![](assets/images/nivedita.jpg){.picture .lightbox}

### Nivedita Harisena

*Doctoral Researcher*

[{{< iconify fa6-solid house-chimney-user size=xl >}}](https://irl.ethz.ch/people/person-detail.Mjg5Mjgx.TGlzdC8zNzc5LC0xMzk1OTgzMDM3.html){.iconify-icon}
[{{< iconify fa6-solid envelope size=xl >}}](mailto:nharisena@ethz.ch){.iconify-icon}
[{{< iconify fa6-brands linkedin size=xl >}}](https://www.linkedin.com/in/nivedita-varma-harisena-667298141/){.iconify-icon}
[{{< iconify fa6-brands github size=xl >}}](https://github.com/NVHarisena1){.iconify-icon}
:::

::: g-col-6
![](assets/images/Manuel.jpg){.picture .lightbox}

### Manuel Kurmann

*Research Assistant*

[{{< iconify fa6-solid house-chimney-user size=xl >}}](https://irl.ethz.ch/people/person-detail.MjM2NjYz.TGlzdC8zNzc5LC0xMzk1OTgzMDM3.html){.iconify-icon}
[{{< iconify fa6-solid envelope size=xl >}}](mailto:mankurma@student.ethz.ch){.iconify-icon}
[{{< iconify fa6-brands linkedin size=xl >}}](https://www.linkedin.com/in/manuel-kurmann-696577251/){.iconify-icon}
[{{< iconify fa6-brands github size=xl >}}](https://github.com/ManuelKurmann){.iconify-icon}
:::

::: g-col-6
![](assets/images/Maarten.jpg){.picture .lightbox}

### Maarten Van Strien

*Senior scientist*

[{{< iconify fa6-solid house-chimney-user size=xl >}}](https://irl.ethz.ch/people/person-detail.MTYzODAz.TGlzdC8xNzM4LC0xMzk1OTgzMDM3.html){.iconify-icon}
[{{< iconify fa6-solid envelope size=xl >}}](mailto:vanstrien@ethz.ch){.iconify-icon}
[{{< iconify fa6-brands linkedin size=xl >}}](https://www.linkedin.com/in/maarten-van-strien-347b6747/?originalSubdomain=ch){.iconify-icon}
[{{< iconify fa6-brands researchgate size=xl >}}](https://www.researchgate.net/profile/Maarten-Van-Strien){.iconify-icon}
:::
:::

## What is reproducible research?

Reproducibility is a key aspect of reliable scientific research. It
enables other researchers to reproduce the same results using the
original data, code, and documentation [@essawy2020]. Below are the core
principles to ensure reproducibility in research:

**Starts with planning**

Reproducibility begins during the planning stage. It is essential to
organize data management and ensure clear protocols are in place even
before starting the analysis. Consistent Data Storage Regular backups of
data are crucial. Storing data in multiple locations ensures
accessibility and minimizes the risk of data loss. [@alston2021]

**Contains clear documentation**

Thorough documentation is essential to guarantee that data and methods
can be accurately interpreted and reproduced by others. This entails the
use of well-organised files and the inclusion of metadata that describes
the data, how it was obtained, and how it was processed.
[@alston2021][@siraji2023]

**Utilizes version control**

Using version control systems helps track changes in the project over
time. This approach preserves the history of the project and facilitates
the reversion of files to a previous state in the event of an error.
[@alston2021]

**Is accessible**

Data should be stored in nonproprietary, portable formats to ensure
broad accessibility and long-term usability. This practice ensures that
researchers can access the data without relying on specific software
tools. Making data and code publicly available in accessible
repositories supports scientific transparency and allows broader use of
research outputs. [@alston2021][@siraji2023]

By following these steps, researchers contribute to the wider scientific
community, ensuring that their work can be efficiently and accurately
reproduced by others.

**Introducing the FAIR Principles**

While the principles above lay the groundwork for reproducibility, the
FAIR principles (Findability, Accessibility, Interoperability, and
Reusability) provide a more comprehensive framework for enhancing the
value of research data in the digital age. These principles expand on
reproducibility by emphasizing not only human access to research outputs
but also machine actionability, ensuring that data can be effectively
found, accessed, and reused by both people and computational tools​.
[@wilkinson2016]

**How FAIR Principles Build on Reproducibility**

The FAIR principles naturally complement and expand on the core aspects
of reproducible research:

-   Findability reinforces the importance of clear documentation.
    Assigning persistent identifiers and providing rich metadata makes
    it easier for researchers and search tools to locate and understand
    datasets, ensuring that your research remains accessible over time.
    
-   Accessibility builds on the concept of using nonproprietary formats.
    FAIR emphasizes that data should be retrievable using open,
    standardized protocols, which ensures long-term access to both the
    data and its metadata, even if the data itself becomes unavailable.
    
-   Interoperability relates to the consistent use of data standards and
    version control. By using standardized formats and vocabularies,
    research data can be more easily integrated with other datasets,
    supporting reuse and long-term relevance in broader research
    contexts.
    
-   Reusability directly aligns with the goals of reproducible research
    by ensuring that data is accompanied by clear licensing and
    provenance, allowing others to confidently reuse it. This principle
    reinforces the need for thorough documentation and transparent
    methods.

By incorporating the FAIR principles, researchers ensure that their data
not only meets the standards of reproducibility but is also optimized
for long-term use and discovery. This fosters a research environment
where data is more transparent, accessible, and impactful over time​.
[@wilkinson2016]

## Why strive for reproducible research?

In recent years, various scientific disciplines have experienced what is
known as a "replication crisis". This crisis arises when researchers are
unable to reproduce the headline results of key studies using the
reported data and methods [@moonesinghe2007][@collaboration2015]
[@bohannon2015]. This lack of reproducibility undermines public trust in
science, as it raises doubts about the validity of research findings.

### Advantages of Reproducibility for Your Research

**Personal Reference**

Conducting reproducible research simplifies the process of remembering
how and why specific analyses were performed. This makes it easier to
explain your work to collaborators, supervisors, and reviewers,
enhancing communication throughout your project. [@alston2021]

**Efficient**

Modifications Reproducible research enables you to quickly adjust
analyses and figures when requested by supervisors, collaborators, or
reviewers. This streamlined process can save substantial time during
revisions. [@alston2021]

**Streamlined Future Projects**

By maintaining well-organized and reproducible systems, you can reuse
code and organizational structures for future projects. This reduces the
time and effort required for similar tasks in subsequent research.
[@alston2021]

**Demonstrates Rigor and Transparency**

Reproducibility demonstrates scientific rigor and transparency. It
allows others to verify your methods and results, improving the peer
review process and reducing the risk of errors or accusations of
misconduct. [@alston2021]

**Increases Impact and Citations**

Making your research reproducible can lead to higher citation rates
[@piwowar2007] [@mckiernan2016]. By sharing your code and data, you
enable others to reuse your work, broadening its impact and increasing
its relevance in the scientific community. [@whitlock2011]
[@culina2018].

### Advantages of Reproducibility for Other Researchers

**Facilitates Learning**

Sharing data and code helps others learn from your work more easily. New
researchers can use your data and code as a reference, speeding up their
learning curve and improving the quality of their analyses.
[@alston2021]

**Enables Reproducibility**

Reproducible research makes it simpler for others to reproduce and build
upon your work, fostering more compatible and robust research across
studies. [@alston2021]

**Error Detection**

By allowing others to access and review your data and code,
reproducibility helps detect and correct errors, ensuring that mistakes
are caught early and reducing the chance of their propagation in future
research. [@alston2021]

## Why {{< iconify fa-brands r-project >}} for reproducible research?

R is increasingly recognized as a powerful tool for ensuring
reproducibility in scientific research. Here are some key advantages of
using R for reproducible research:

**Open Source**

Accessibility R is freely available to everyone, eliminating cost
barriers and promoting inclusive access to research tools. This
open-source model ensures that researchers around the world can use and
contribute to its development, fostering a collaborative research
environment. [@siraji2023]

**Comprehensive Documentation**

R encourages thorough documentation of the entire research process. This
ensures that analyses are well-tracked and can be easily replicated
across different projects, enhancing the overall transparency and
reliability of the research.

**Integrated Version Control**

R seamlessly integrates with version control systems like Git, allowing
researchers to track changes to code, data, and documents. This helps
maintain a detailed record of a project's evolution and ensures that all
steps are easily reproducible. [@siraji2023]

**Consistency Across Platforms**

R provides a stable environment that works consistently across different
operating systems, whether you are using Windows, Mac, or Linux. This
cross-platform consistency greatly enhances the reproducibility of
research across diverse systems.

**Broad Community Support**

The R community is large and active, continuously contributing to the
improvement of the software. This broad support makes R a reliable
choice for long-term research projects, ensuring that new tools and
methods are constantly being developed and shared.

**Flexibility and Adaptability**

R offers a wide range of tools and functions that can be adapted to
various research needs. This flexibility allows researchers to handle
diverse tasks within a reproducible framework, making it a versatile
tool for projects of all kinds.
:::

<!-- Presentation content -->

::: {.content-visible when-format="revealjs"}
## About us

::::{.columns .v-center-container}

::: {.column width="50"}
![](assets/images/Ben_headshot.jpg){.picture width="80%"}
<br>**Ben Black**
<br>Doctoral researcher
:::

::: {.column width="50"}
![](assets/images/Manuel.jpg){.picture width="80%"}
<br>**Manuel Kurmann**
<br>Research assistant
:::
::::

# Your turn:<br>Introduce yourselves and what institution you are from.

# What is reproducible research?
<br>Let's hear your thoughts: What does reproducible research mean to you?

## The FAIR standard

-   **F**indability, **A**ccessibility, **I**nteroperability, and
    **R**eusability[@wilkinson2016].

-   Developed by diverse stakeholders (academia, industry, funders,
    publishers).

-   Addressed the need for infrastructure supporting data reuse.

-   Emphasis on both human and machine readability.

## Why strive for reproducible research?

-   **Replication crisis**: Allows our work to be verified more thoroughly
-   **Improves science for all**: Allows others to more easily build upon
    our work

**Don't just take our word for it, research funders are increasingly
focused on reproducible research too.**

## Why <img style="vertical-align:-35%; height:0.85em;" src="assets/images/Rlogo.png"> for reproducible research?

-   Open source
-   Large active user community for support
-   Packages to suit just about every research need: statistics,
    modelling, spatial analysis, visualisation (Many packages developed
    by academics)

**But just using <img style="vertical-align:-35%; height:0.85em;" src="assets/images/Rlogo.png"> doesn't necessarily
make your research reproducible...**

# Tell us a bit about your experience with <img style="vertical-align:-30%; height:0.85em;" src="assets/images/Rlogo.png">?

## Workshop concept

![](assets/images/graphical_abstract_dark.png){width="70%" fig-align="center"}
:::



# Research projects with R



---
execute:
  echo: true
  eval: false
  error: false
---


<!-- Web content -->

::: {.content-hidden when-format="revealjs"}
**Let's start with a definition of what makes a good R project from Jenny Bryan:**

A good R project... *"creates everything it needs, in its own workspace or folder, and it touches nothing it did not create."* [@bryan2017]

This is a good definition that contains concepts, such as the notion that projects should be 'self-contained'. However we add one more caveat to this definition which is that a good R project should *explain itself*.

For the purpose of this workshop we will approach this topic by splitting it up into 6 topics which are highlighted in this graphic:

![Graphical overview of components of a good research project in R](assets/images/project_components.png)

As you move through these you will see that there are areas of overlap and complementarity between them. These topics are also central to the choice of approaches in the [three workflows for reproducibility](@sec-workflows) that we will share.

## <img src="assets/images/Rstudio.light.svg" style="vertical-align:middle; height:1.5em;"/> projects {#sec-projects}

How many times have you opened an R script and been greeted by this line:


```{r}
#| eval: false
setwd("C:/Users/ben/path/that/only/I/have")
```


While it is well-intentioned (i.e. avoiding the need to have full paths for all objects that will subsequently be loaded or daved ) the problem with it is obvious: This specific path is only relevant for the author and not other potential users and even for the author it will be invalid if they happen to change computers. The good news is there is a very simple way to avoid having to use `setwd()` at all by using [**Rstudio Projects**]().

Rstudio projects designate new or existing folders as a defined working directory by creating an `.RProj` file within them. This means that when you open a project the working directory of the Rstudio session will automatically be set to the directory that the .RProj file is located in and the paths of all files in this folder will be relative to this.

The `.Rproj` file can be shared along with the rest of the research project files meaning that others users can easily open the Project to have the same working directory removing the need for those troublesome `setwd()` lines.

### Creating and opening projects {#sec-creating-projects}

Creating an Rstudio project is as simple as using *File \> New Project* in the top left and then choosing between creating the Project in a new or existing directory.

There are several ways to open a Project:

1.  Using *File \> Open Project* in the top left of Rstudio.

![](assets/images/File_open_project.png){fig-align="center" width="50%"}

2.  Using the drop down menu in the top-right of the Rstudio session.

![](assets/images/Open_project_right.png){fig-align="center" width="50%"}

3.  Outside of R by double clicking on the `.Rproj` file in the folder.

![](assets/images/Open_project_explorer.png){fig-align="center" width="50%"}

### Utilising project specific `.Rprofile`'s {#sec-rprofile}

Another useful feature of Rstudio projects is the ability to store project-specific settings using the `.Rprofile` file which controls the initialisation behaviour of the R session when the project is opened. A useful application of this for reproducible research projects is automatically open a particular script, for example a master script that runs all the code in the project (which is a concept that will discussed under [workflow decomposition](@sec-workflow-decomposition)).

To do this the contents of your `.Rprofile` file would like this:


```{r}
#| eval: false
setHook("rstudio.sessionInit", function(newSession) {
  if (newSession)
    # Open the script specificed by the path
    rstudioapi::navigateToFile('scripts/script_to_open.R', line = -1L, column = -1L)
}, action = "append")
```


The easiest way to create and edit `.Rprofile` files is to use the functions from the package [`usethis`](https://usethis.r-lib.org/):


```{r}
#| eval: false
# Note the use of scope = "project" to create a project specific .Rprofile
usethis::edit_r_profile(scope = "project")
```


## Environment management {#sec-environment-management}

These lines of code are also probably familiar from the beginning of many an R script:


```{r}
#| eval: false
install.packages("ggplot2")
library(ggplot2)
```


But what is wrong with these lines?

Well firstly, there is no indication of what version of the package is to be installed and hence if the code installing this package is old it may not work with the most recent version of the package (This is less of a problem for well established packages like the Tidyverse but for less common packages, that may see large changes between versions, it could be substantial).

Secondly, having the user install an unspecified version of a package could also cause dependency conflicts with other packages required by the code. This is because almost all packages have some form of dependency (i.e. they use the functionality of) on other packages. This is shown aptly by the image below which, while out-dated now, showed that in 2014 to install the 7 most popular R packages at the time would actually install 63 packages in total when considering their dependencies.

![Package dependencies of popular R package [@devries2014]](assets/images/package_dependencies_2.png){width="50%" fig-align="center"}

However the problem is bigger than just packages because when your code runs it is also utilising:

-   A specific version of R

-   A specific operating system

-   Specific versions of system dependencies, i.e. other software in other languages that R packages themselves utilise e.g GDAL for spatial analysis packages like `terra`.

All of these things together make up what is known as the 'environment' of your code. Hence the process of documenting and managing this environment to is ensure that your code is reproducible (i.e. it not only runs but also consistently produces the same results).

There are different approaches to environment management that differ in their complexity and hence maybe suited to some projects and not others. For the purpose of this workshop we will focus on what we have found is one of the most user-friendly ways to manage your *package environment* (caveat that will be discussed) in R which is the package `renv`. Below we will introduce this package in more detail as it will form a central part of the [three workflows for reproducibility](@sec-workflows) that we present.

### Creating reproducible environments with `renv`

As mentioned above [`renv`](https://rstudio.github.io/renv/articles/renv.html) is an R package that helps you create reproducible environments for your R projects by not only documenting your package environment but also providing functionality to re-create it.

It does this by creating **project specific libraries** (i.e. directories: `renv/library`) which contain all the packages used by your project. This is different from the default approach to package usage and installation whereby all packages are stored in a single library on your machine (system library). Having separate project libraries means "that different projects can use different versions of packages and installing, updating, or removing packages in one project doesn't affect any other project." [@renv]. In order to make sure that your project uses the project library everytime it is opened `renv` utilises the functionality of [`.Rprofile's`](@sec-rprofile) to set the project library as the default library.

Another key process of renv is to create project specific **lockfiles** (`renv.lock`) which contain sufficient metadata about each package in the project library so that it can be re-installed on a new machine.

As alluded to, renv does a great job of managing your packages but is not intended to manage other aspects of your environment such as: tracking your version of R or your operating system. This is why if you want 'bullet-proof' reproducibility renv needs to be used alongside other approaches such as containerization which is the [3rd and most complex workflow](@sec-docker_workflow) we will discuss.

## Writing clean code {#sec-writing-clean-code}

The notion of writing 'clean' code can be daunting, especially for those new to programming. However, the most important thing to bear in mind is that there is no objective measure that makes code 'clean' vs. 'un-clean', rather we should of think 'clean' coding as the pursuit of making your code easier to read, understand and maintain. Also while we should aspire to writing clean code, it is arguably more important that it functions correctly and efficiently.

The central concept of clean coding is that, like normal writing, we should follow a set of rules and conventions. For example, in English a sentence should start with a capital letter and end with a full stop. Unfortunately, in terms of writing R code there is not a single set of conventions that everyone proscribes to, instead there are numerous styles that have been outlined and the important thing is to choose a style and apply it consistently in your coding.

Perhaps the two most common styles are the [Tidyverse style](https://style.tidyverse.org/) and the [Google R style](https://google.github.io/styleguide/Rguide.html) (Which is actually a derivative of the former). Neither style can be said to be the more correct, rather they express opinionated preferences on a series of common topics such as: Object naming, use of assignment operators, spacing, indentation, line length, parentheses placement, etc.

Rather than detail all of these topics here we will focus on just on some related tips that we think are most relevant for scientific research coding, including how to automate the formatting of your code to a particular style. However, we encourage you to go through the different style guides when you have the time.

### Script headers {#sec-script_headers}

Starting your scripts with a consistent header containing information about it's purpose, author/s, creation and modification dates is a great step making your workflow more understandable and hopefully reproducible. There are no rules as to what such a header should look like but this is the style I like to use:


```{r}
#############################################################################
## Script_title: Brief description of script purpose
##
## Notes: More detailed notes about the script and it's purpose
##
## Date created: 
## Author(s):
#############################################################################
```


To save time inserting this header into new scripts you use Rstudio's [**Code snippets**](https://docs.posit.co/ide/user/ide/guide/productivity/snippets.html) feature. Code snippets are simply text macros that quickly insert a section of code using a short keyword.

To create your own Code snippet go to *Tools \> Global Options \> Code \> Edit Snippets* and then add a new snippet with your code below it:

![](assets/images/Code_snippet_add.png){fig-align="center" width="50%"}

To use a code snippet simply start typing the keyword in the script and the auto-completion list will appear then press `Tab` and the code section will be inserted:

![](assets/images/Code_snippet_completion.png){fig-align="center" width="50%"}

### Code sections {#sec-code_sections}

As you may already know braced (`{}`) sections of code (i.e. function definitions, conditional blocks, etc.) can be folded to hide their contents in RStudio by clicking on the small triangle in the left margin.

![](assets/images/code_section_sequential.png){fig-align="center" width="50%"}

However, an often overlooked feature is the ability to create named code sections that can be also folded, as well as easily navigated between. These can be used to break longer scripts into a set of discrete regions according to specific parts of the analysis ([discussed in more detail later](@sec-workflow-decomposition)). In this regard, another good tip is to give the resulting sections sequential alphabetical or numerical Pre-fixes. Code sections are created by inserting a comment line that contains at least four trailing dashes (`-`), equal signs (`=`), or pound signs (`#`):


```{r}

# Section One ---------------------------------
 
# Section Two =================================
 
# Section Three #############################
```


Alternatively you can use the *Code \> Insert Section* command.

To navigate between code sections:

-   Use the **Jump To** menu available at the bottom of the editor[@positsupport2024]

![](assets/images/code_section_jumpto.png){fig-align="center"}

-   Use the document outline pane in the top right corner of the source pane

![](assets/images/code_section_documentpane.light.png){fig-align="center"}

### Automating the styling of your code

There are two R packages that are very helpful in terms of ensuring your code confirms to a consistent style: [`lintr`](https://lintr.r-lib.org/) and [`styler`](https://styler.r-lib.org/).

-   `lintr` checks your code for common style issues and potential programming errors then presents them to you to correct, think of it like doing a 'spellcheck' on a written document.
-   `styler` is more *active* in the sense that it automatically format's your code to a particular style, the default of which is the tidyverse style.

To use lintr and styler you call their functions like any package but styler can also be used through the **Rstudio Addins** menu below the Navigation bar as shown in this gif:

![](https://raw.githubusercontent.com/lorenzwalthert/some_raw_data/master/styler_0.1.gif){fig-align="center" width="70%"}

Another very useful feature of both packages is that they can be used as part of a continuous integration (CI) workflow using a version control application like Git. This is a topic that we will cover as part of our [Version control with Git](@sec-git_workflow) workflow but what it means is that the styler and lintr functions are run automatically when you push your code to a remote repository.

## Workflow decomposition {#sec-workflow-decomposition}

In computer sciences workflow decomposition refers to the structuring or compartmentalising of your code into seperate logical parts that makes it easier to maintain [@decompos2024].

In terms of coding scientific research projects many of us probably already instinctively do decomposition to some degree by splitting typical processes such as data preparation, statistical modelling, analysis of results and producing final visualizations.

However this is not always realized in the most understandable way, for example we may have seperate scripts with logical sounding names like: `Data_prep.R` and `Data_analysis.R` but can others really be expected to know exactly which order these must be run in, or indeed whether they even need to be run sequentially at all?

A good 1st step to remedying this is to give your scripts sequential numeric tags in their names, e.g. `01_Data_prep.R`, `02_Data_analysis.R`. This will also ensure that they are presented in numerical order when placed in a designated directory [Structuring your project directory](@sec-structuring) and can be explicitly described in your [project documentation](@sec-documentation).

But you can take this to the next level by creating a *Master* script that sources your other scripts in sequence (think of them as *sub-scripts*) so that users of your code need only run one script. To do this is as simple as creating the master script as you would any normal R script (*File \> New File \> R script*) and then using the `base::source()` function to run the sub-scripts:


```{r}
#| eval: false
#############################################################################
## Master_script: Run steps of research project in order
##
## Date created: 30/7/2024
## Author(s): Jane Doe
#############################################################################

### =========================================================================
### A- Prepare dependent variable data
### =========================================================================

#Prepare LULC data
source("Scripts/Preparation/Dep_var_dat_prep.R", local = scripting_env)

### =========================================================================
### B- Prepare independent variable data
### =========================================================================

#Prepare predictor data
source("Scripts/Preparation/Ind_var_data_prep.R", local = scripting_env)

### =========================================================================
### C- Perform statisical modelling
### =========================================================================

source("Scripts/Modelling/Fit_stat_models.R", local = scripting_env)

```


As you can see in this example code I have also made use of a [script header](@sec-script_headers) and [code sections](@sec-code_sections), that were previously discussed, to make the division of sub-processes even clearer. Another advantage of this approach is that all sub-scripts can utilise the same environment (defined by the `source(local= )` argument) which means that each individual script does not need to load packages or paths as objects.

Finally, within your sub-scripts processes should also be seperated into code sections and ideally any repetitive tasks should be performed with custom functions which again are contained within their own files.

Following this approach you end up with a workflow that will look something like this:

![](assets/images/workflow_decomposition.png){width="100%"}

The benefit of this hierarchical approach to structuring is that it is not only easier to debug and maintain individual processes but it is also more amenable to adding new processes.

## Structuring your project directory {#sec-structuring}

Similar to having clean code, having a clean project directory that has well-organised sub-directories goes a long way towards making your projects code easier to understand for others. For software development there are numerous sets of conventions for directories structures although these are not always so applicable for scientific research projects. However we can borrow some basic principles, try to use: - Use logical naming - Stick to a consistent style, i.e. use of captialisation and seperators - Make use of nested sub-directories e.g `data/raw/climatic/precipitation/2020/precip_2020.rds` vs. `data/precip_2020_raw.rds`. This is very helpful when it comes to programatically constructing file paths especially in projects with a lot of data.

As an example my go-to project directory structure looks like this:


```{r}
#| eval: false
└── my_project
    ├── data # The research data
    │   ├── raw
    │   └── processed
    ├── output # Storing results
    ├── publication # Containing the academic manuscript of the project
    ├── src # For all files that perform operations in the project
    │   ├── scripts
    │   └── functions
    └── tools # Auxilliary files and settings
```


Rather than manually create this directory structure everytime you start a new project, save yourself some time and automate it by using Rstudio's [**Project Templates**](https://docs.posit.co/ide/user/ide/guide/productivity/project-templates.html) functionality. This allows you to select a custom template as an option when creating a new [Rstudio project](@sec-creating-projects) through the New project wizard (*File \> New Project \> New Directory \> New Project Template*).

To implement this even as an intermediate R user is fairly labor intensive as your custom project directory template needs to be contained within an R-package, in order to be available in the wizard. However, quite a few templates with directory structures appropriate for scientific research projects have been created by others:

-   [`rrtools`](https://github.com/benmarwick/rrtools)

-   [`ProjectTemplate`](http://projecttemplate.net/)

-   [`template`](https://pakillo.github.io/template/)

-   [`addinit`](https://dreamrs.github.io/addinit/) (Not a template but an interactive shiny add-in for project creation)

## Project documentation {#sec-documentation}

As an example of why documentation is important think about if you bought a new table from Ikea only to excitedly rip open the box and find that there are no instructions for how to assemble it. Sure, you know what a table is supposedly to look like and given enough time you will end up with something that will probably be mostly right but maybe it's missing small details. Also it will probably take you just as long to take it apart in 5 years time. Well, working with undocumented code for research projects is similar except a lot more complicated!

Writing comprehensive documentation that covers all aspects of our projects is time-consuming which is why it is often neglected. For example, there are a lot of different metadata conventions that exist that you could apply. However, learning and adhering strictly to these can be overwhelming and possibly lead to the opposite effect i.e. they are not simple for others to understand either.

In response to this there has been a movement in the R research community to adopt the *research as package* approach, which, as the name suggests, involves creating your project as an R-package which has a strict set of conventions for documentation [@marwick2018]. This is a viable approach for those who are familiar with R-packages but is arguably not the best for all projects and users.

Instead, we would suggest to follow the maxim of *not letting the perfect be the enemy of the good* and to focus on these key areas:

-   **Provide adequate in-script commentary**: This is perhaps contentious for those from a software development community, but given the choice I would rather have to read through a script with too many comments than one with too few. However remember that comments should be used to explain the purpose of the code, not what the code is doing. In line with this use [script headers](@sec-script_headers).

-   **Document your functions with `roxygen` skeletons**:

-   **Include a `README` file**: README files are where you should document your project at the macro-level i.e. what it is about and how it is supposed to work.

The latter of these two are more detailed so we have provided further information and tips in sections below.

### Function documentation with `roxygen2` {#sec-roxygen}

Base R provides a standard way of documenting a package where each function is documented in an `.Rd` file (R documentation). This documentation uses a custom syntax to detail key aspects of the functions such as their input parameters, outputs and any package dependencies [@wickham2024].

In the case of many research projects you will not be creating a package however it is still useful to apply this documentation style to your functions as it is a good way to make them understandable and easier to modify by others. For example, having clear information about the object (e.g. a vector or data.frame) that a function accepts, saves others time in guessing what the function is expecting if they are trying to use new data.

However, rather than manually writing `.Rd` files, we can use the `roxygen2` package to automatically generate these files from a block of comments that are added to the top of the function scripts. To add this comment block, place your cursor inside a function you want to document and press `Ctrl + Shift + R` (or `Cmd + Shift + R` on Mac) or you can go to *code tools \> insert roxygen skeleton* (code tools is represented by the wand icon in the top row of the source pane). As you can see in this gif below, when you insert the roxygen block it will already contain the names of the function, its arguments and any returns. You can then fill in the rest of the information, such as the description and dependencies etc. for a guide to these other fields see the [roxygen2 documentation](https://roxygen2.r-lib.org/articles/rd.html).

![Inserting roxygen block](https://jozef.io/img/r102-01-add-roxy-skeleton.gif){width="50%"}

### Tips for README writing

If you look at the source code of R packages or projects that use R in Github repositories you will see that they all contain `README.md` files. `.md` is [Markdown](https://en.wikipedia.org/wiki/Markdown) format which is the most common format for README files in R projects because it can be read by many programs and rendered in a variety of formats. These files are often accompanied by the corresponding file `README.Rmd` which generates the `README.md` file. In this sense writing the README for your project in markdown makes sense and there tools available to help you do this such as the `usethis` package which has a function [`use_readme_rmd()`](https://usethis.r-lib.org/reference/use_readme_rmd.html) that will create a `README.Rmd` file for you. However, depending on who you anticipate using your project you may also want to create your README as a raw text file (`.txt`) which may be a more familiar format for some users and again can be opened by many different programs.

Again there is not a single standardised format for what should be included in your README file but here is an example of a README file that was written for one of the authors code/data upload alongside a publication: [README.txt](assets/README_demo.txt)

You will see that one of the things this README includes is a tree diagram which shows the directory structure of the project right down to the file level. This is a useful way to give an overview of what users should find included in the project and then explanatory notes can be added to explain the purpose of each file or directory. Such a diagram can be easily generated using the `fs` package:


```{r}
#| eval: false
install.packages("fs")
library(fs)

#vector path of the target directory to make a file tree from
Target_dir <- "YOUR DIR"

#produce tree diagram of directory sub-dirs and files and save output using capture.ouput from base R utils.
capture.output(dir_tree(Target_dir), file= 'Dir_tree_output.txt')
```

:::

<!-- Presentation content -->

::: {.content-visible when-format="revealjs"}
## Research projects with R

::: r-fit-text
**Jenny Bryan:** A good R project... *"creates everything it needs, in its own workspace or folder, and it touches nothing it did not create."* [@bryan2017]

-   Projects should be 'self-contained'
-   Additional caveat: a good R project should *explain itself*.
:::

## Research projects with R

![Graphical overview of components of a good research project in R](assets/images/project_components.png)

::: notes
-   We will approach this topic by splitting it up into 6 topics which are highlighted in this graphic.
-   As we move through the 6 topics you will see that there are areas of overlap and complementarity between them.
-   These topics are also central to the choice of approaches in the three workflows for reproducibility that we will share.
:::

## 1. Rstudio projects

::: r-fit-text
Recognise this?


```{r}
#| eval: false
#| echo: true
setwd("C:/Users/ben/path/that/only/I/have")
```


But what's the problem with it?

::: incremental
-   This path is only relevant for the author and not other users.
-   Even for the author it will be invalid if they change computers.
:::
:::

## 1. Rstudio projects

**Stay away from `setwd()!`**

**Use [Rstudio Projects](https://support.posit.co/hc/en-us/articles/200526207-Using-RStudio-Projects)**:

-   Designates new or existing folders as working directory creating an `.RProj` file within them.

-   When you open a project the working directory will automatically be set and all paths will be relative to this.

-   The `.Rproj` can be shared along with the rest of the research project, users can easily open the project to have the same working directory.

## 1. Rstudio projects

### Creating projects

Go to *File \> New Project*, can be created in a new or existing directory

![](assets/images/create_project.png){fig-align="center"}

## 1. Rstudio projects

### Opening projects

Using *File \> Open Project* in the top left of Rstudio.

![](assets/images/File_open_project.png){fig-align="center"}

## 1. Rstudio projects

### Opening projects

Using the drop down menu in the top-right of the Rstudio session.

![](assets/images/Open_project_right.png){fig-align="center"}

## 1. Rstudio projects

### Opening projects

Outside of R by double clicking on the `.Rproj` file in the folder.

![](assets/images/Open_project_explorer.png){fig-align="center"}

## 1. Rstudio projects

### Utilising project specific `.Rprofile`'s

-   Rstudio projects can store project-specific settings using the `.Rprofile` file.

-   File is run every time the project is opened, can be used to perform actions such as opening a particular script:


```{r}
#| eval: false
#| echo: true
setHook("rstudio.sessionInit", function(newSession) {
  if (newSession)
    # Open the script specificed by the path
    rstudioapi::navigateToFile('scripts/script_to_open.R', line = -1L, column = -1L)
}, action = "append")
```


## 1. Rstudio projects

### Utilising project specific `.Rprofile`'s

The easiest way to create and edit `.Rprofile` files is to use the functions from the package [`usethis`](https://usethis.r-lib.org/):


```{r}
#| eval: false
#| echo: true
# Note the use of scope = "project" to create a project specific .Rprofile
usethis::edit_r_profile(scope = "project")
```


## 2. Environment management

Familiar lines from the beginning of many an R script:


```{r}
#| eval: false
#| echo: true
install.packages("ggplot2")
library(ggplot2)
```


Again, what is wrong?

## 2. Environment management

::: {.column width="50%"}
**No indication of version of package to be installed =**

-   Potential for to break code

-   Introduce dependency conflicts
:::

::: {.column width="50%"}
![Package dependencies of popular R package [@devries2014]](assets/images/package_dependencies_2.png){width="80%" fig-align="center"}
:::

::: notes
No indication of what version of package is to be installed and hence if the code installing this package is old it may not work with the most recent version of the package (This is less of a problem for well established packages like the Tidyverse but for less common packages, that may see large changes between versions, it could be substantial).

Secondly, having the user install an unspecified version of a package could also cause dependency conflicts with other packages required by the code. This is because almost all packages have some form of dependency (i.e. they use the functionality of) on other packages.

This is shown aptly by the image below which, while out-dated now, showed that in 2014 to install the 7 most popular R packages at the time would actually install 63 packages in total when considering their dependencies.
:::

## 2. Environment management

**But the problem is bigger than just packages...**

When your code runs it is also utilizing:

-   A specific version of R

-   A specific operating system

-   Specific versions of system dependencies, i.e. other software that R packages utilise.

Collectively, these are the **Environment** of your code, documenting and managing this is essential ensure reproducibilty

## 2. Environment management

**But how to manage your environment?**

-   Different approaches that range in complexity hence maybe suited to some projects and not others.

-   Most user-friendly way to manage your *package environment* (caveat to be discussed) in R: `renv` package.

::: notes
renv will form a central part of the three workflows for reproducibility that we will present later.
:::

## 2. Environment management

### Creating reproducible environments with `renv`

[`renv`](https://rstudio.github.io/renv/articles/renv.html) helps you create reproducible environments for your R projects by:

-   Documenting your package environment

-   Providing functionality to re-create it.

## 2. Environment management

### Creating reproducible environments with `renv`

-   Normally all your R packages are stored in a single library on your machine (system library).
-   `renv` creates a project specific libraries of packages (`renv/library`) which contain all the packages used by your project.
-   `renv` also creates project specific **lockfiles** (`renv.lock`) which contain sufficient metadata so that the project library can be re-installed on a new machine.

**Result**: Different projects can use different versions of packages and installing, updating, or removing packages in one project doesn't affect any other project.

## 2. Environment management

### `renv` limitation

`renv` is not intended to manage **other aspects of your environment** such as: tracking your version of R or your operating system.

This is why if you want 'bullet-proof' reproducibility `renv` needs to be used alongside other approaches such as containerization.

## 3. Writing clean code

-   There is no objective measure that makes code 'clean' vs. 'un-clean'.

-   Think of 'clean coding' as the pursuit of making your code easier to **read, understand and maintain**.

![](assets/images/clean_code_meme.png){fig-align="center"}

## 3. Writing clean code

### Code styles

-   Like writing, code should follow a set of rules and conventions. For example, in English, a sentence starts with a capital letter and ends with a full stop.

-   For R code there is not a single set of conventions instead there are numerous styles. Two most common are the [Tidyverse style](https://style.tidyverse.org/) and the [Google R style](https://google.github.io/styleguide/Rguide.html).

**Most important: Choose a style and apply it consistently in your coding.**

## 3. Writing clean code

### Code styles

Code styles express opinionated preferences on a series of common topics:

-   Object naming
-   Use of assignment operators
-   Spacing
-   Indentation
-   Line length
-   Parentheses placement

We won't discuss in detail but you should read one of the style guides when you have the time.

::: notes
Code styles express opinionated preferences on a series of common topics such as: Object naming, use of assignment operators, spacing, indentation, line length, parentheses placement, etc.

Rather than detail all of these topics here we will focus on just on some related tips that we think are most relevant for scientific research coding, including how to automate the formatting of your code to a particular style. However, we encourage you to go through the different style guides when you have the time.
:::

## 3. Writing clean code

### Automating the styling of your code

Two R packages for code styling, [`lintr`](https://lintr.r-lib.org/) and `styler`:

-   `lintr` checks your code for style issues and potential programming errors then presents them to you to correct, like doing a 'spellcheck' on a written document.
-   `styler` automatically format's your code to a particular style, the default of which is the tidyverse style.

## 3. Writing clean code

### Automating the styling of your code

-   To use `lintr` and `styler` call their functions like any package

-   `styler` can also be used through the **Rstudio Addins** menu below the Navigation bar: <img src="https://raw.githubusercontent.com/lorenzwalthert/some_raw_data/master/styler_0.1.gif" style="display: block; margin-left: auto; margin-right: auto;"/>

-   Both packages can be used as part of a continuous integration (CI) workflow with Github, meaning that their functions can be run automatically when you update your code.

## 3. Writing clean code

### Script headers

-   Starting your scripts with a consistent header containing information about it's purpose, author/s, creation and modification dates is very helpful!

-   There are no rules as to what this should look like but this is an example:

```{{r}}
#############################################################################
## Script_title: Brief description of script purpose
##
## Notes: More detailed notes about the script and it's purpose
##
## Date created: 
## Author(s):
##################################################################
```

## 3. Writing clean code

### Script headers

::: {.column width="60%"}
-   To save time inserting your script header use Rstudio's [**Code snippets**](https://docs.posit.co/ide/user/ide/guide/productivity/snippets.html) feature.

-   Code snippets are text macros that insert a section of code using a keyword.

-   To create your own Code snippet go to *Tools \> Global Options \> Code \> Edit Snippets* and then add a new snippet with your code below it
:::

::: {.column width="40%"}
![](assets/images/Code_snippet_add.png){fig-align="center"}
:::

## 3. Writing clean code

### Script headers

To use a code snippet simply start typing the keyword in the script and the auto-completion list will appear then press `Tab` and the code section will be inserted:

![](assets/images/Code_snippet_completion.png){fig-align="center" width="50%"}

## 3. Writing clean code

### Code sections

-   Braced (`{}`) sections of code (i.e. function definitions, conditional blocks, etc.) can be folded to hide their contents by clicking on the small triangle in the left margin:

![](assets/images/code_section_sequential.png){fig-align="center" width="50%"}

-   But you can also create custom named **code sections** to break longer scripts according to specific parts of the analysis.

## 3. Writing clean code

### Code sections

-   Code sections are created by inserting a comment line that contains at least four trailing dashes (`-`), equal signs (`=`), or pound signs (`#`):


```{r}

# Section One ---------------------------------
 
# Section Two =================================
 
# Section Three #############################
```


-   Alternatively you can use the *Code \> Insert Section* command.

## 3. Writing clean code

### Code sections

To navigate between code sections:

-   Use the **Jump To** menu available at the bottom of the editor[@positsupport2024]

![](assets/images/code_section_jumpto.png){fig-align="center"}

## 3. Writing clean code

### Code sections

To navigate between code sections:

-   Use the **document outline pane** in the top right corner of the source pane

![](assets/images/code_section_documentpane.dark.png){fig-align="center"}

## 4. Workflow decomposition

-   Workflow decomposition is the structuring or compartmentalising of code into seperate logical parts that makes it easier to maintain [@decompos2024].

-   You probably already instinctively do decomposition by splitting typical processes such as:

    -   Data preparation
    -   Statistical modelling
    -   Analysis of results
    -   Producing final visualizations

-   This oftens leads to scripts with logical sounding names like: `Data_prep.R` and `Data_analysis.R` but can others be expected to know which order these must be run in?

## 4. Workflow decomposition

**Solutions:**

-   **1st step**: Give your scripts sequential numeric tags in their names, e.g. `01_Data_prep.R`, `02_Data_analysis.R` ensuring that they are presented in numerical order in their designated directory.

-   **Next level**: Create a *Master* script that sources your other scripts in sequence (think of them as *sub-scripts*) so that users need only run one script.

## 4. Workflow decomposition

-   To do this create the master script as you would any normal R script (*File \> New File \> R script*) and then use the `base::source()` function to run the sub-scripts:


```{r}
#| eval: false
#| echo: true
#############################################################################
## Master_script: Run steps of research project in order
#############################################################################

#Prepare LULC data
source("Scripts/Preparation/Dep_var_dat_prep.R", local = scripting_env)

#Prepare predictor data
source("Scripts/Preparation/Ind_var_data_prep.R", local = scripting_env)
```


-   Another advantage of this approach is that all sub-scripts can utilise the same environment (defined by the `source(local= )` argument).

## 4. Workflow decomposition

-   Within your sub-scripts processes should also be seperated into code sections and any repetitive tasks should be performed with custom functions.

-   Following this approach you end up with a workflow that will look something like this:

![](assets/images/workflow_decomposition.png){fig-align="center"}

::: notes
The benefit of this hierarchical approach to structuring is that it is not only easier to debug and maintain individual processes but it is also more amenable to adding new processes.
:::

## 5. Structuring your project directory

-   A clean project directory that has well-organised sub-directories makes your projects code easier to understand for others.

-   Try to use:

    -   Logical naming
    -   A consistent style (i.e. use of captialisation and seperators).
    -   Nested sub-directories e.g `data/raw/climatic/precipitation/2020/precip_2020.rds` vs. `data/precip_2020_raw.rds` (helpful when it comes to programatically constructing file paths)

## 5. Structuring your project directory

As an example my go-to project directory structure looks like this:


```{r}
#| eval: false
#| echo: true
└── my_project
    ├── data # The research data
    │   ├── raw
    │   └── processed
    ├── output # Storing results
    ├── publication # Containing the academic manuscript of the project
    ├── src # For all files that perform operations in the project
    │   ├── scripts
    │   └── functions
    └── tools # Auxilliary files and settings
```


## 5. Structuring your project directory

-   Creation of project directory structure can be automated using using Rstudio's [**Project Templates**](https://docs.posit.co/ide/user/ide/guide/productivity/project-templates.html) functionality.

-   Allows selection of custom template when creating a new Rstudio project (*File \> New Project \> New Directory \> New Project Template*).

-   **Warning**: Implementation of personal template is labor intensive as it needs to be contained within an R-package. But several template packages appropriate for scientific research projects are available:

    -   [`rrtools`](https://github.com/benmarwick/rrtools)
    -   [`ProjectTemplate`](http://projecttemplate.net/)
    -   [`template`](https://pakillo.github.io/template/)
    -   [`addinit`](https://dreamrs.github.io/addinit/)

## 6. Project documentation

![[Singer 2024](https://andysinger.com/)](assets/images/documentation_cartoon.jpg){fig-align="center"}

## 6. Project documentation

But writing comprehensive documentation that covers all aspects of projects is time-consuming...

**Suggested solution in the R research community:** *Research as package* approach (i.e. creating your project as an R-package) [@marwick2018].

**Pro**: R-packages have an existing strict set of conventions for documentation

**Cons**:

-   Learning curve for those unfamiliar with R-packages

-   May not be appropriate for all project requirements.

## 6. Project documentation

Our advice: *don't let the perfect be the enemy of the good* and focus on these key areas:

-   **Provide adequate in-script commentary**: Remember that comments should be used to explain the purpose of the code, not what the code is doing

-   **Document your functions with `roxygen` skeletons**

-   **Include a `README` file**: README files are where you should document your project at the macro-level i.e. what it is about and how it is supposed to work.

::: notes
The latter of these two are more detailed so we have provided further information and tips in sections below.
:::

## 6. Project documentation

### Function documentation with `roxygen2`

-   `base` R provides a standard way of documenting functions in packages as seperate `.Rd` (R documentation) files.

-   `.Rd` files use a custom syntax to detail key aspects of the functions such as input parameters, outputs, package dependencies [@wickham2024].

-   Documenting functions in this way is a good practice for your project even if you are not creating a package.

::: notes
In the case of many research projects you will not be creating a package however it is still useful to apply this documentation style to your functions as it is a good way to make them understandable and easier to modify by others. For example, having clear information about the object (e.g. a vector or data.frame) that a function accepts, saves others time in guessing what the function is expecting if they are trying to use new data.
:::

## 6. Project documentation

### Function documentation with `roxygen2`

-   Rather than manually create `.Rd` files, we can use the `roxygen2` package.

-   `roxygen2` provides functionality to add blocks of comments (`roxygen skeleton`) to the top of the function scripts. These are then used to automatically generate `.Rd` files.

-   To add a `roxygen skeleton`, place your cursor inside a function you want to document and press `Ctrl + Shift + R` (or `Cmd + Shift + R` on Mac) or you can go to *code tools \> insert roxygen skeleton* (wand icon in the top row of the source pane).

::: notes
However, rather than manually writing `.Rd` files, we can use the `roxygen2` package to automatically generate these files from a block of comments that are added to the top of the function scripts. To add this comment block, place your cursor inside a function you want to document and press `Ctrl + Shift + R` (or `Cmd + Shift + R` on Mac) or you can go to *code tools \> insert roxygen skeleton* (code tools is represented by the wand icon in the top row of the source pane).
:::

## 6. Project documentation

### Function documentation with \`roxygen2

-   When you insert the roxygen block it will already contain the names of the function, its arguments and any returns. You can then fill in the rest of the information, such as the description and dependencies etc.

![Inserting roxygen block](https://jozef.io/img/r102-01-add-roxy-skeleton.gif){fig-align="center"}

## 6. Project documentation

### Tips for README writing

-   R packages or projects typical have `README.md` files.
-   `.md` is the [Markdown](https://en.wikipedia.org/wiki/Markdown) format which is the most common format for README files in R projects because it can be read by many programs and rendered in a variety of formats.
-   `README.md` files are often accompanied by the corresponding file `README.Rmd`, an Rmarkdown file which generates them.
-   `README.Rmd` files can be created using the `usethis` package ([`use_readme_rmd()`](https://usethis.r-lib.org/reference/use_readme_rmd.html)).
-   However, depending on anticipated project users creating the README as a raw text file (`.txt`) may be better.

::: notes
These files are often accompanied by the corresponding file `README.Rmd` which generates the `README.md` file. Markdown format is used for README's because it can be read by many programs and rendered in a variety of formats. In this sense writing the README for your project in markdown makes sense and there tools available to help you do this such as the `usethis` package which has a function [`use_readme_rmd()`](https://usethis.r-lib.org/reference/use_readme_rmd.html) that will create a `README.Rmd` file for you. However, depending on who you anticipate using your project you may also want to create your README as a raw text file (`.txt`) which may be a more familiar format for some users and again can be opened by many different programs.
:::

## 6. Project documentation

### Tips for README writing

-   No single standardised format for what should be included but here is an example of a [README.txt](assets/README_demo.txt) file from one of the authors publications.

-   Useful to include a tree diagram of the project directory structure down to the file level:

`{r}{.smaller} #| eval: false #| echo: true ├── Data │   ├── Processed │   │   └── RiceFarms_summary.csv │   └── Raw │       └── RiceFarms.csv ├── Output │   └── Regional_size_summary_bar.png └── Scripts     ├── 01_data_analysis.R     └── 02_data_visualisation.R`

::: notes
You will see that one of the things this README includes is a tree diagram which shows the directory structure of the project right down to the file level. This is a useful way to give an overview of what users should find included in the project and then explanatory notes can be added to explain the purpose of each file or directory. Such a diagram can be easily generated using the `fs` package:
:::

## 6. Project documentation

### Tips for README writing

-   Such a diagram can be easily generated using the `fs` package:


```{r}
#| eval: false
#| echo: true
install.packages("fs")
library(fs)

#vector path of the target directory to make a file tree from
Target_dir <- "Your_dir"

#produce tree diagram of directory sub-dirs and files and save output using capture.ouput from base R utils.
capture.output(dir_tree(Target_dir), file= 'Dir_tree_output.txt')
```


## Summary

Now this some of the details of the graphical overview probably make more sense to you:

![](assets/images/project_components.png){fig-align="center"}

**We will implement some of these good practices in our 1st exercise.**
:::



# Let's take a 10 minute break!

# Workflows for Reproducibility

## Workflows for Reproducibility

We will discuss three workflows for reproducibility:

::: incremental
1.  Rstudio project to Zenodo pipeline

2.  Containerization with Docker

3.  Version control with Git
:::

::: fragment
These are suggestions for different approaches and we hope that in future you will be able to adapt these workflows to the needs of your own research projects.
:::



---
execute:
  echo: true
  eval: false
  error: false
---


<!-- Web content -->

::: {.content-hidden when-format="revealjs"}

![](assets/images/project_zenodo_workflow.png){.lightbox width="70%" fig-align="center"}

The graphic above shows the main steps of this workflow. It starts by
developing your research project as an Rstudio project following the
[good practice project guidelines](@sec-Rprojects) we have discussed.
Then, it uses the `renv` package to manage the project environment so
that others can re-create it. Finally, the code, data and environment
are uploaded to the open-access repository `Zenodo`, which provides a
DOI for your work, ensuring long-term accessibility and reproducibility.

The `renv` package helps maintain the R environment, allowing others to
recreate the environment in which your analysis was conducted. By
combining `renv` with Zenodo, you create a comprehensive solution for
reproducible research. `renv` ensures that the computational environment
is captured, while Zenodo makes your research outputs accessible and
citable, supporting the FAIR principles of findability, accessibility,
interoperability, and reusability [@wilkinson2016].

The next sections provide some additional detail on [environment
management with renv](@sec-renv_workflow) and some background and
practical tips on [Zenodo](@sec-zenodo_background). You will have the
chance to apply this workflow to an example project in the [accompanying
exercise](@sec-Rproj_zenodo_exercise).

### Environment Management with `renv` {#sec-renv_workflow}

`renv` is a powerful R package designed to help manage project
environments by creating project-specific libraries and lockfiles. As
mentioned earlier, `renv` captures the exact versions of R packages used
in a project, storing this information in a renv.lock file. This allows
users to recreate the exact package environment when revisiting a
project or transferring it to a different machine, ensuring
reproducibility.

The `renv` workflow is straightforward:

-   **Initialize `renv` in a project**: `renv` creates a separate
    library in the project folder, isolating the packages from the
    system-wide library.

-   **Snapshot dependencies**: `renv` scans the project, identifying
    which packages are being used and recording their versions in the
    lockfile.

-   **Restore environments**: Anyone cloning or receiving the project
    can run `renv::restore()` to install the exact versions of the
    packages listed in the lockfile from the project library,
    reproducing the original project package environment.

One of the core strengths of `renv` is its flexibility. It integrates
seamlessly with tools like RStudio, allowing easy management of
dependencies without disrupting existing workflows. This makes it
particularly well-suited for ensuring that research projects are
reproducible across different systems and platforms.

However, `renv` does not manage the **entire system environment** (such
as the version of R itself or external dependencies like system
libraries). For complete reproducibility, combining `renv` with

containerization tools (like [Docker](@#sec-docker_workflow)) or publishing outputs (such as code
or data) via repositories like Zenodo is recommended.

### <img src="assets/images/zenodo-blue.svg" style="vertical-align:middle; height:2.75em;"/> as a research repository {#sec-zenodo_background}

[Zenodo](https://zenodo.org/) is a platform created under the European
Commission‘s [OpenAIRE project](https://www.openaire.eu/) in partnership
with [CERN](https://home.cern/) to publish, archive, and share
scientific research outputs, including datasets, code, and publications.

Of course there are many other similar research repositories, such as
[Dryad](https://datadryad.org/stash), [Figshare](https://figshare.com/),
[Mendeley Data](https://data.mendeley.com/) and
[OSF](https://osf.io/q5j8g/), but we recommend Zenodo for several
reasons:

-   **Generous upload size of 50GB (100 files) per record**

-   **Aligns with FAIR and Open Science principles**: The practical
    features of Zenodo that ensure this are described in it‘s
    [principles](https://about.zenodo.org/principles/)

-   **Ability to create communities**: [Zenodo
    Communities](https://help.zenodo.org/docs/communities/about-communities/)
    are used to group similar records together. This is useful for
    creating a collection of related research outputs, either for a
    research group or a large-scale funded project.

-   **Long term preservation with assignment of DOIs:** Each item
    published on Zenodo is assigned a permanent [*Digital Object
    Identifier*
    (DOI)](https://simple.wikipedia.org/wiki/Digital_Object_Identifier),
    which is a better way than a URL to cite the record in academic
    writing.

-   **Open source**: This means that Zenodo is not just free to use
    but you can even see the [code it is built
    on](https://github.com/zenodo/zenodo-rdm) and contribute to it.

-   **Versioning functionality:** Every record starts with a 1st version
    and [new versions can be added as research is
    updated](https://help.zenodo.org/docs/deposit/manage-versions/),
    while earlier versions remain accessible. This is crucial in
    scientific research, where updated analyses and data corrections are
    often necessary, but also transparency around earlier versions of
    the work should be maintained.

-   **Integration with GitHub:** When a research project (e.g., code) is
    hosted on [GitHub](@sec-git_workflow), Zenodo can be used to
    [archive the
    repository](https://help.zenodo.org/docs/profile/linking-accounts/)
    upon each new release, creating a snapshot with a DOI. This means
    that a version of the code can be more easily cited in scientific
    publications.

-   **Application programming Interface (API) to access records
    programmatically:** This a useful feature as it allows for
    interfacing with Zenodo records without using the website and is
    the backbone of the `zen4R` package that allows for publishing
    records directly from R which we discuss in more detail below.

### Publishing to Zenodo with `zen4R`


The [`zen4R`](%3Chttps://cran.r-project.org/web/packages/zen4R) package
[@blondel2024] provides functions to interact with `Zenodo‘s` API
directly from R. The package allows you to:

-   Retrieve the metadata of, and download, existing `Zenodo` records.

-   Create new records and versions of records, write their metadata and
    upload files to `Zenodo`.

We will use `zen4R` to publish the code, data, and environment of our
example project to `Zenodo` in the accompanying exercise.
:::

<!-- Presentation content -->

::: {.content-visible when-format="revealjs"} 

## Rstudio project to `Zenodo` pipeline

![](assets/images/project_zenodo_workflow.png){.lightbox width="90%"
fig-align="center"}

::: notes
This visualization introduces the main steps of this workflow. It starts
by developing your research project as an Rstudio project following the
good practice guidelines we have just discussed. Then, it uses the renv
package to manage the project environment so that others can re-create
it. Finally, the code, data and environment are uploaded to the
open-access repository `Zenodo`, which provides a DOI for your work,
ensuring long-term accessibility and reproducibility.
:::

## Rstudio project to `Zenodo` pipeline

### Managing Project Environments with renv

-   `renv` creates project-specific libraries

-   Captures package versions in a `renv.lockfile`

-   Ensures reproducibility of package environment

-   Centralizes package environment management within each project

::: notes
-   `renv` helps to manage R projects by creating isolated libraries containing just the packages and the versions, that are used in the specific project.

-   For each project a renv.lockfile is created. The renv.lock file records exact versions of all packages in use, allowing consistent installation of these packages to improve reproducibility.

-   This feature is especially useful for transferring projects between machines, maintaining a controlled environment.

-   renv also isolates the projects library from the library of your regular r installation. This prevents conflicts with previously installed packages on your machine not related to your project.

:::

## Rstudio project to `Zenodo` pipeline

### `renv` Workflow

-   Initialize `renv` inside the project directory to identify
    dependencies using `renv::init()`

-   Snapshot dependencies to create a lockfile using `renv::snapshot()`

-   Restore environments using `renv::restore()`

-   Easy integration with RStudio for workflow management

::: notes
-   Initialize `renv` in a project to isolate packages from the system-wide library.

-   Snapshot the project’s package dependencies, generating a lockfile (renv.lock).

-   Restore the environment by reinstalling packages using the lockfile.

-   `renv` integrates smoothly with RStudio, making it easy to use alongside other development tools.
:::

## Rstudio project to `Zenodo` pipeline

### Limitations of `renv`

-   Does not manage R versions or system-wide dependencies

-   Focuses on managing package environments within R

-   Best combined with containerization (e.g., `Docker`) for full
    reproducibility

-   Complements external repositories (e.g., `Zenodo`) for sharing and
    preservation

::: notes
-   `renv` does not manage system-level dependencies such as the R version or other software your project might rely on (e.g., geospatial libraries like GDAL

-   `renv` is designed to manage the R package environment, ensuring that the same R packages and versions are used across different machines.

-   For full reproducibility, `renv` should be combined with tools like `Docker` for system environment control.

-   Publishing platforms like `Zenodo` can be used to store code and data for long-term preservation.

:::

## Rstudio project to `Zenodo` pipeline

### Publishing and Archiving with Zenodo

-   Long-term storage with generous 50GB upload limit per record

-   Permanent DOIs for easy citation and versioning support for updates

-   GitHub integration for seamless code archiving with DOI snapshots

-   Supports FAIR principles: aligned with open access, transparency,
    and reusability

-   Community creation for grouping related research outputs

-   API and open-source: flexible for programmatic access and
    customization

::: notes
-   `Zenodo` provides long-term storage for a variety of research outputs, including datasets, code, and publications, ensuring that these materials remain accessible over time.

-   Every record receives a permanent Digital Object Identifier (DOI), which allows for easy citation in research papers.

-   Integration with GitHub allows researchers to archive their code and generate DOI-linked snapshots with each release.

-   `Zenodo` aligns with the FAIR and Open Science principles, supporting open and reusable research outputs

-   The platform allows the creation of communities to group related records, making it useful for creating a collection of related research outputs, either for a research group or a large-scale funded project.

-   `Zenodo’s` API provides programmatic access for tasks like automating record creation, and its open-source nature allows for customization and contribution to the platform.

:::

## Rstudio project to `Zenodo` pipeline

### Streamlining publishing to `Zenodo` with `zen4R`

-   Upload datasets, code, and metadata from R to `Zenodo`

-   Automate publication and deposition management

-   Retrieve and update `Zenodo` records directly in R

-   Facilitates integration and reproducibility in R workflows

::: notes
-   `zen4R` allows R users to interact with `Zenodo‘s` API to upload data and code directly from R.

-   It supports automated publication, including metadata management and updating of records

-   Access `Zenodo` records programmatically within R.

-   This makes publishing more efficient, especially in workflows requiring frequent updates.

:::

## Rstudio project to `Zenodo` pipeline

### Combining `renv` and `Zenodo`

-   `renv` manages internal project environments

-   `Zenodo` ensures external reproducibility with archiving

-   Together, they provide a comprehensive solution

-   Aligns with open science and FAIR principles

::: notes
-   `renv` manages internal environments by locking package versions and dependencies.

-   `Zenodo` provides external storage and ensures reproducibility by archiving and versioning research outputs.

-   Together, they create a comprehensive solution for reproducible, open science projects.

-   This combination aligns with FAIR principles, ensuring data is Findable, Accessible, Interoperable, and Reusable.

:::

:::



---
execute:
  echo: true
  eval: false
  error: false
---


<!-- Web content -->

::: {.content-hidden when-format="revealjs"}
![](assets/images/Docker_workflow.png){.lightbox width="90%" fig-align="center"}

**The title of this workflow raises two questions, the first being: what is containerization? and the second: what is Docker?** \### Containerisation

Simply put containerization is the process of bundling code along with all of it's dependencies, i.e. all the components we discussed as making up the [environment](@sec-environment-management), including the operating system, software libraries (packages), and other system software. The fact everything needed to run the code is included means that the code is portable and can be run on any platform or cloud service. This also makes containerization something of a gold standard for reproducibility as the entire environment is explicitly re-produced.

### Docker

[Docker](https://www.docker.com/) is an open-source, and the most popular, platform for containerization. Before we dive into a practical example using Docker for research projects with R it is important to introduce some three key terms that we will come across:

-   `Dockerfile`: The first step in the containerization process, they are a straightforward text file containing a collection of commands or procedures to create a new Docker Image. In this sense we can consider a Dockerfile are the source code of Docker Image. Importantly, Dockerfiles typically start from a base image, which is a existing Docker Image that your image is extending.

-   `Docker Image`: A read-only file that contains the instructions for creating a Docker Container. Think of an image as the blueprint of what will be in a container when it is running. Docker Images can be shared via [Dockerhub](https://hub.docker.com/), so that they can be used by others.

-   `Docker Container`: Is an actual running instance of a Docker image. It runs completely isolated from the host environment by default and only accesses host files (i.e. data) if it has been configured to do so. It is possible to create multiple containers simultaneously from the same Docker Image, and each container can be started, stopped, moved, and deleted independently of the others.

The graphic above shows the relationships between these components including the central commands of Docker that connect them `build` and `run`.

### Using Docker with R

So to create a `Docker Image` to containerize our R research projects we need to start by creating a `Dockerfile` and, as mentioned above, this should start with a base image. In our case this base image must logically include R and RStudio (if we want to utilise the RStudio Projects features).

Fortunately there is a project that specifically catalogs and manages Docker Images for R projects: [`Rocker`](https://rocker-project.org/). The images available through the Rocker project not only include different versions of R and RStudio but also images containing collections of R packages for specific purposes (e.g. tidyverse for data wrangling and visualisation, geospatial packages etc.).

In terms of actually creating the `Dockerfile` for our R project, this can be done manually (See a good R-focused tutorial[here](https://colinfay.me/docker-r-reproducibility/)), however there are also R packages that can help with this process such as [`dockerfiler`](https://thinkr-open.github.io/dockerfiler/) and the `[rrtools`\](https://github.com/benmarwick/rrtools) package.

For our [exercise](@sec-docker_exercise) of this workflow we will use the `dockerfiler` package, which creates a custom class object that represents the Dockerfile and has slots corresponding to common elements of Docker images. This allows us to add elements to the dockerfile in a more R-like way. The following code snippet demonstrates adding `Maintainer` details to a `Dockerfile` object, before saving it:


```{R}
#| eval: false
#| echo: true
library(dockerfiler)
# Create a dockerfile template
my_dock <- Dockerfile$new()

# Add maintainer
my_dock$MAINTAINER("Jane Doe", "jane_doe@gmail.com")

# Save
my_dock$write()
```


### Docker with `renv`

Docker can be used with the `renv` package to [manage the package environment of your project](@sec-environment-management).

There are two methods of implementing this which come with their own considerations:

1.  **Use `renv` to install packages when the Docker image is built**: This approach is useful if you plan to have multiple projects with **identical package requirements**. This because by creating an image containing this package library you can simply re-use the image as a base for new images for different projects [@ushey2024].**Warning:** Restoring the package library (`renv::restore()`) when building the image will be slow if there are large numbers of packages so try to avoid the need to re-build the base image many times.

2.  **Use `renv` to install/restore packages only when Docker containers are run**: This approach is better when you plan to have multiple projects that are built from the same base image but require **different package requirements**. Hence it is preferable to not included the package library in the image but instead to mount different project specific libraries to the container when it is run [@ushey2024]. If project libraries are dynamically provisioned in this way and `renv::restore()` is run with caching this means that the packages are not re-installed everytime the container is run.
:::

<!-- Presentation content -->

::: {.content-visible when-format="revealjs"}
# Containerization with Docker

## Containerization with Docker

### What is containerization?

Containerization is the process of bundling code along with all of it's dependencies including:

-   The operating system

-   Software libraries (packages)

-   Other system software

Everything needed to run the code is included means that the code is portable and can be run on any platform or cloud service.

**This makes containerization the gold standard for reproducibility**

## Containerization with Docker

### What is Docker?

::: {.columns .v-center-container}
::: {.column width="50%"}
[Docker](https://www.docker.com/) is an open-source, and the most popular, platform for containerization.
:::

::: {.column width="50%"}
![](assets/images/Docker_light_blue.png){fig-align="center"}
:::
:::

## Containerization with Docker

![](assets/images/Docker_workflow.png){fig-align="center" width="80%"}

`Dockerfile`:

-   Text file containing a collection of commands to create a new Docker Image.
-   Includes the details of the environment required to create to run the code and the command to do it.
-   Typically start from a base image, i.e an existing Docker Image.

## Containerization with Docker

![](assets/images/Docker_workflow.png){fig-align="center" width="80%"}

`Docker Image`:

-   A read-only file that contains the instructions for creating a Docker Container.
-   *Blueprint* of what will be in a container when it is running.
-   Docker Images can be shared via [Dockerhub](https://hub.docker.com/), so that they can be used by others.

## Containerization with Docker

![](assets/images/Docker_workflow.png){fig-align="center" width="80%"}

`Docker Container`:

-   A running instance of a Docker image that runs code with it's environment
-   Runs in isolation from the host, only accesses host files (i.e. data) if it has been configured to do so.
-   Possible to create multiple containers simultaneously from the same Docker Image.

::: notes
-   `Docker Container`: Is an actual running instance of a Docker image. It runs completely isolated from the host environment by default and only accesses host files (i.e. data) if it has been configured to do so. It is possible to create multiple containers simultaneously from the same Docker Image, and each container can be started, stopped, moved, and deleted independently of the others.
:::

## Containerization with Docker

### Using Docker with R

Two main resources that can help in the creation of containerized R projects:

1.  [`Rocker`](https://rocker-project.org/):

-   A project that catalogs and manages Docker Images for R projects.

-   Basic images include different versions of R and RStudio

-   Other images offering collections of R packages for specific purposes (e.g. tidyverse).

## Containerization with Docker

### Using Docker with R

Two main resources that can help in the creation of containerized R projects:

2.  `Dockerfile`:

-   A package which creates a custom class object that represents the `Dockerfile`

-   Has slots corresponding to common elements of Docker images allowing to add elements to the dockerfile in R.

## Containerization with Docker

### Docker with `renv`

Two methods of integrating `renv` with Docker to manage the package environment of your project:

1.  Use `renv` to install packages when the Docker image is built:

-   Useful for multiple projects with **identical package requirements** because you can re-use the image as a base for new images[@ushey2024].
-   Restoring the package library (`renv::restore()`) when building the image is slow so try to avoid the need to re-build the base image many times.

## Containerization with Docker

### Docker with `renv`

Two methods of integrating `renv` with Docker to manage the package environment of your project:

2.  Use `renv` to install/restore packages only when Docker containers are run:

-   Better when you plan to have multiple projects built from the same base image but with **different package requirements**.

-    Package library is not included in the image but instead different project specific libraries are mounted to the container when it is run [@ushey2024].

-   If `renv::restore()` is run with caching, packages are not re-installed everytime the container is run.
:::



---
execute:
  echo: true
  eval: false
  error: false
---


::: {.content-hidden when-format="revealjs"}

![](assets/images/version_control_workflow.png){width="70%" fig-align="center"}

**Version control** software output can have multiple uses including creating a systematic procedure for collaboration, working as a team along with increasing the ease of reproduction of the work by other users or by the original researcher as well. We all know the difficulty of tracing back the workflow of work projects a few months down the line after having shelved it, and it is here that Git and Github can be highly useful (@Alexander2023).

### About Git

**Git** allows us to make snapshot or record of the changes undertaken in a script, and store it as with a message that defines the change. In this way even after multiple updates, the history is preserved allowing us to revert, compare and systematically trace back the workflow development.

**Git** is useful also for data scientists and researchers that work individually yet want to create systematically reproducible workflows with version control (@Alexander2023).

### GitHub repositories and functionalities {#sec-Gitrepo}

The version controlled code and all other auxiliary files related to the project are stored in a Github repository which was created by the user in their account on Github. A repository can either be set as public or private as per the users need for visibility of their work.

To help with version control Github repositories provide multiple functionalities like creating 'branches', 'clones', 'merging' multiple branches, setting up a 'pull request' before merge etc. As we get into more complicated workflows handled by multiple developers, Github allows many more functionalities as checks and balances to code development. However, we will limit our understanding to what is needed to create work with a version control history allowing for small scale collaboration, but with the main goal of creating reproducible research ([see more details](https://docs.github.com/en/repositories/creating-and-managing-repositories/about-repositories)).

### Basic functionalities

-   **Creating a repository and setting up user authorisations**: A project repository must first be set up on GitHub as either a private or a public repository. If it is not an individual project, collaborators can be added with appropriate (read or write) permission levels ([see more details](https://docs.github.com/en/account-and-profile/setting-up-and-managing-your-personal-account-on-github/managing-user-account-settings/permission-levels-for-a-personal-account-repository)). It is good to elaborate the 'Readme' file so as to help viewers get an idea of the repository ([see more details](https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-readmes)).

-   **Push and Pull**: The data and code related to a project must be cloned from the remote version to a local version before changes are made. Make sure to pull from updated (i.e. merged branches; see below) branches before making changes. Once changes are made the user must 'commit' all the correct changes. Once this is done the changed code can be pushed back to the branch.

-   **Branching and merging** : Git allows users to create [branches](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-branches#working-with-branches) that feed into the 'main' branch of a project repository on GitHub. Each branch can be created either for different tasks or for different users as per the requirement. To [merge branches into 'main' users have to set up a pull-request](https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/configuring-pull-request-merges/about-merge-methods-on-github) which needs to be approved by an authorised user.

-   Git provides additionally **many more [functionalities](https://education.github.com/git-cheat-sheet-education.pdf)** for identifying differences between changed files or between branches, to make temporary commits and to revert back to a certain commit in history. However this is beyond the scope of this workshop.

### Git in R-Studio

When a Github repository is connected to an R project, R-studio adds a 'Git' tab (see image below) with 'push', 'pull', 'commit' and 'diff' functionalities. We can switch branches to pull from or push to and additionally trace the history of changes in the Github respository by all users.

![Git intergration into R-Studio](assets/images/screenshot_R_studio_git.png){width="70%" fig-align="center"}

Alternatively you can also use [Github desktop](https://github.com/apps/desktop) to perform the same functionalities.

### Additional functionalities

1.  Public Github repositories can now be archived on Zenodo as a permanent record of the work with a Digital Object Identifier (DOI) that can be cited in academic work ([Click to see more details](https://docs.github.com/en/repositories/archiving-a-github-repository/referencing-and-citing-content)).

2.  GitHub further provides advanced functionalities like [GitHub Actions](https://docs.github.com/en/actions/about-github-actions/understanding-github-actions) that allows the user to automate certain processes for application development or project management.

3.  GitHub releases can be automatically published on Docker Hub or GitHub packages as part of a Continuous Integration(CI) workflow ([see more details](https://docs.github.com/en/actions/use-cases-and-examples/publishing-packages/publishing-docker-images)).
:::

::: {.content-visible when-format="revealjs"}

## Version control with Github

### Why Git and GitHub?

-   **Version control**: A more systematic way to organise data beyond "dataprep_1", "dataprep_final", "dataprep_finalfinal" etc.

-   **Systematic documentation** and **storage of code** changes allowing us to track changes and revert back to previous versions when needed.

::: notes
Git is a version control system that tracks changes whereas Github is a cloud based online platform that hosts git repositories.

Version control is also the main reason for most people to use Git and Github. This simplifies managing different versions of your code. Instead of manually creating copies of your files, Git handles this for you, allowing you to work with a single file on your computer without the worry of messing up a previously working version.

Additionally, Git  tracks changes over time, documenting who made the changes and why. This is helpful if multiple people work on a project. If mistakes occur or you need to revisit earlier versions, Git lets you revert to previous states.
:::

## Version control with Github

### Terminologies

-   **Push** and **Pull**?

![Git terminologies](assets/images/Git_terminology.png){width="70%" fig-align="center"}

-   Git cheatsheet: https://education.github.com/git-cheat-sheet-education.pdf

::: notes
Think of branches as separate working spaces, but still about the same work. There is a main branch storing your results. Each additional branch can be used to test changes without affecting the main output. Once you’re satisfied you can then merge your changes into the main branch. This let’s you test new things and fix bugs without worrying to mess up the main branch. Also, it helps to avoid conflicts if several people work on the same project.
:::

## Version control with Github

### Steps for using Git and GitHub (To be done in the exercises - basic)

-   Create a GitHub repository in your account

-   Download and install Git

-   Add credentials for your account to Git

-   Link RProject to Github repository

-   Open, checkout and navigate Git repository local version via Rstudio

-   Basic functionalities of Git in Rstudio

::: notes
The process involves setting up a GitHub repository, installing Git, linking it with your account, and then connecting your R project to the repository. From there, you can manage the repository through RStudio, using basic Git functionalities to track and control changes.
:::

## Version control with Github

### Additional fucntionalities

-   GitHub repositories can be archived on Zenodo and thus get a DOI.
-   GitHub actions
-   GitHub releases can be continuously integrated into DockerHub or GitHub Packages

::: notes

- GitHub Actions is a powerful automation tool integrated into GitHub. It allows you to automate actions based on triggers. For example every time code is pushed or pulled or at a certain time of day. For example if you have a website with quarto you can automatically rerender the website if a push is performed.

- GitHub releases can be integrated into platforms like **DockerHub** or **GitHub Packages**. This means you can automatically build and publish Docker containers or software packages directly from your GitHub releases
:::
:::



# Quarto



---
execute:
  echo: false
  eval: true
  error: false
  output: true
  include: true
---


<!-- Web content -->

::: {.content-hidden when-format="revealjs"}
::: columns
::: {.column width="70%"}
[Quarto](https://quarto.org/) is an open source scientific and technical publishing system developed by [Posit](https://posit.co/) the same company that also created Rstudio. Quarto allows you to integrate code in multiple programming languages, with written material, and a wide variety of interactive visual components into a range of different document formats. If you are familiar with [Rmarkdown](https://rmarkdown.rstudio.com/) then you will find Quarto familiar as it is in many ways an evolution of this.

The Quarto website presents [many examples](https://quarto.org/docs/gallery/) of the application of the software but here we will focus on some of it's key uses and features that are relevant for academics and producing reproducible research.
:::

::: {.column width="30%"}
![](assets/images/quarto_diamond_logo.png){fig-align="center" width="70%"}
:::
:::

### Writing academic manuscripts

We all know how painful it can be switching between multiple programs to produce academic manuscripts, maybe you write your text in word, and produce your visualizations in R or Python before having to convert the end result to PDF for submission. This is especially annoying when you need to update parts of the manuscript as part of the review process.

Quarto solves this problem by allowing you to write full academic manuscripts from start to finish including text, code, and visualizations in a single program. This functionality has been expanded even further with the release of [Quarto Manuscripts](https://quarto.org/docs/manuscripts/) as a project type from Quarto version 1.4.

Some key benefits of writing your manuscript with Quarto include:

-   Figures and tables are dynamically updated as your code changes

-   Supports the use and inclusion of R, Python and Julia code as well as LaTeX and Markdown

-   Simple cross-referencing capability for figures, tables, and sections

-   Documents can be rendered as Word, PDF, or HTML

-   Easily include citations and bibliographies from Crossref, DataCite, and PubMed as well as with direct integration with [Zotero](https://www.zotero.org/)

-   High quality formatting options for equations and tables

-   Quarto's `.qmd` files can be edited with various code/text editors including VS Code, RStudio and more

-   Track changes and collaborate using Git or other version control systems.

Writing your academic manuscripts with Quarto is more reproducible as it allows others to use your underlying manuscript file in combination with your data to directly re-create your results.

In one of our exercises you will practice [creating a manuscript with Quarto for an example project](@sec-Quarto_exercise)

### Presentations with RevealJS

Quarto also allows you to create presentations in several formats [RevealJS](https://revealjs.com/), [Microsoft Powerpoint](https://quarto.org/docs/presentations/powerpoint.html) and [Beamer](https://quarto.org/docs/presentations/beamer.html) using a common syntax. In fact the [presentation document](https://blenback.github.io/R-for-Reproducible-Research/presentation.html) for this workshop is created using Quarto and RevealJS.

Some useful features of making presentations with Quarto include:

-   Selection of pre-existing modern themes with functionality to publish your own theme.

-   Include interactive content: Executable code blocks and visual components (graphs and maps)

-   Dynamic resizing of content depending on screen size

-   Functionality for slide notes, automatic transitions, timers etc.

-   Easy export to PDF or HTML

-   Similar to manuscripts code-based content is dynamically updated.

### Websites

Quarto can also be used to create websites that can be freely hosted through Github Pages or other services like Netlify or Posit Connect. This is a great way to share your research with a wider audience or promote your work. Creating Quarto websites is an intuitive and user-friendly process and because it uses the [Bootstrap](https://getbootstrap.com/docs/5.0/getting-started/introduction/) framework there is a lot of guidance available for customizing beyond the 25 default themes

Some examples from the authors:

-   This website is created with Quarto and hosted on Github Pages and you can see all of it's source code [here](https://github.com/blenback/R-for-Reproducible-Research).

-   This is an example of personal website created by Ben to share publications, presentations and blog content: <https://blenback.github.io/>

![Researchers personal website](assets/images/Personal_website.gif){fig-align="center" width="70%"}

-   This is a Multi-lingual website created for a research project in Peru to share progress and results of the project: <https://nascent-peru.github.io/>.

![NASCENT-Peru website](assets/images/NASCENT_website.gif){fig-align="center" width="70%"}

### Dashboards to demostrate your research output

[Quarto dashboards](https://quarto.org/docs/dashboards/) allow you to arrange multiple interactive or static components in a single page with a highly customizable layout. These components can include text summaries, tables, plots, maps and more. This is a great way to collect feedback on aspects of your research during the development process or to present your results in a visually appealing way.

Here is an interactive example produced using Python interactive plots:

<figure>

<iframe width="650" height="650" src="https://jjallaire.github.io/gapminder-dashboard/" title="Gapminder dashboard from JJallaire">

</iframe>

<figcaption>Gapminder dashboard from [JJallaire](https://jjallaire.github.io/gapminder-dashboard/).</figcaption>

</figure>

<!-- ![](https://quarto.org/docs/dashboards/examples/thumbnails/customer-churn-dashboard.png){fig-align="center" width="70%"} -->

### Data exploration and visualization

As has been mentioned already Quarto provides a lot of options for creating interactive data visualisations, tables and diagrams using frameworks such as:

-   [Plotly](https://plotly.com/python/)
-   [Leaflet](https://ipyleaflet.readthedocs.io/en/latest/)
-   [Jupyter Widgets](https://ipywidgets.readthedocs.io/en/latest/)
-   [htmlwidgets](https://www.htmlwidgets.org/)
-   [ObservableJS](https://observablehq.com/@observablehq/observables-not-javascript)
-   [Shiny](https://shiny.rstudio.com/)

There are lots of examples of these on the [Quarto website](https://quarto.org/docs/gallery/#interactive-docs) but one we particularly like is Leaflet which allows you to create interactive maps with markers, popups and other features. In a research context this is useful to others to explore the spatial results of your research. Here is a simple example we used to show the locations and timings of workshops we were conducting in Peru.


```{r}
#| code-fold: true
#| echo: true
#| eval: true
#| output: true
#| include: true

library(leaflet)
library(fontawesome)
library(mapview)


national <- makeAwesomeIcon(text = fa("people-roof"),
                              iconColor = 'white',
                              library = 'fa',
                              markerColor = 'darkgreen')
  
regional <- makeAwesomeIcon(text = fa("people-roof"),
                              iconColor = 'white',
                              library = 'fa',
                              markerColor = 'lightgreen')


#uncomment for saving map
#Workshop_locations <- 
  leaflet(options = leafletOptions(zoomControl = FALSE,
                                 attributionControl=FALSE)) %>%
  #addProviderTiles(providers$Esri.WorldTerrain) %>%
  addTiles() %>%  # Add default OpenStreetMap map tiles
  addAwesomeMarkers(lng=-77.043,
                    lat=-12.038,
                    icon= national,
                    popup="Lima, National Workshop 9th May",
                    label = "Lima, National Workshop, 9th May",
                    labelOptions = labelOptions(#noHide = TRUE,
                                                direction = "bottom",
                                                style = list("color" = "black",
                                                "font-family" = "Roboto",
                                                "font-style" = "italic",
                                                "box-shadow" = "3px 3px rgba(0,0,0,0.25)",
                                                "font-size" = "12px",
                                                "border-color" = "rgba(0,0,0,0.5)")))%>%
  addAwesomeMarkers(lng=-69.189, lat=-12.594, icon = regional, popup="Puerto Maldonado, Regional Workshop", label = "Puerto Maldonado Regional Workshop 28th May",
                    labelOptions = labelOptions(#noHide = TRUE,
                                                direction = "bottom",
                                                style = list("color" = "black",
                                                "font-family" = "Roboto",
                                                "font-style" = "italic",
                                                "box-shadow" = "3px 3px rgba(0,0,0,0.25)",
                                                "font-size" = "12px",
                                                "border-color" = "rgba(0,0,0,0.5)")))%>%
  addAwesomeMarkers(lng=-77.529, lat=-9.526, icon = regional, popup="Huaraz, Regional Workshop", label = "Huaraz, Regional Workshop 4th June",
                    labelOptions = labelOptions(#noHide = TRUE,
                                                direction = "bottom",
                                                style = list("color" = "black",
                                                "font-family" = "Roboto",
                                                "font-style" = "italic",
                                                "box-shadow" = "3px 3px rgba(0,0,0,0.25)",
                                                "font-size" = "12px",
                                                "border-color" = "rgba(0,0,0,0.5)")))%>%
  addAwesomeMarkers(lng=-76.370, lat=-6.485, icon = regional, popup="Tarapoto, Regional Workshop", label = "Tarapoto, Regional Workshop 10th June",
                    labelOptions = labelOptions(#noHide = TRUE,
                                                direction = "bottom",
                                                style = list("color" = "black",
                                                "font-family" = "Roboto",
                                                "font-style" = "italic",
                                                "box-shadow" = "3px 3px rgba(0,0,0,0.25)",
                                                "font-size" = "12px",
                                                "border-color" = "rgba(0,0,0,0.5)")))%>%
  addAwesomeMarkers(lng=-80.63282, lat=-5.19449, icon = regional, popup="Piura, Regional Workshop", label="Piura, Regional Workshop 20th May",
                    labelOptions = labelOptions(#noHide = TRUE,
                                                direction = "bottom",
                                                style = list("color" = "black",
                                                "font-family" = "Roboto",
                                                "font-style" = "italic",
                                                "box-shadow" = "3px 3px rgba(0,0,0,0.25)",
                                                "font-size" = "12px",
                                                "border-color" = "rgba(0,0,0,0.5)")))
```

:::

<!-- Presentation content -->

::: {.content-visible when-format="revealjs"}
## Quarto

::: {.columns .v-center-container}
::: {.column width="70%"}
-   An open source scientific and technical publishing system

-   Integrates code in multiple programming languages, written material, and interactive visual components

-   Produces a range of document formats including HTML, PDF, and Word

-   Developed by [Posit](https://posit.co/) the same company that created Rstudio.
:::

::: {.column width="30%"}
![](assets/images/quarto_diamond_logo.png){fig-align="center"}
:::
:::

## Quarto

-   Quarto website presents [many examples](https://quarto.org/docs/gallery/) of it's applications
-   We will focus on some of it's key uses and features that are relevant for academics and producing reproducible research.
    -   Academic manuscripts
    -   Presentations
    -   Websites
    -   Interactive dashboards
    -   Data exploration and visualization

## Quarto

### Writing academic manuscripts

How many programs do you currently use when writing academic papers?

![A common workflow of academic papers [@lusseau2024]](assets/images/trad_paper_workflow.png){fig-align="center"}

## Quarto

### Writing academic manuscripts

Quarto solves this problem by allowing you to write full academic manuscripts from start to finish including text, code, and visualizations in a single document:

![](assets/images/quarto_document_writing.png){fig-align="center"}

## Quarto

### Writing academic manuscripts

Key benefits:

-   Figures and tables are dynamically updated as your code changes

-   Supports code in R, Python and Julia as well as LaTeX and Markdown content

-   Easy Cross-referencing capability for figures, tables, and sections

-   Documents can be rendered as Word, PDF, or HTML

-   Include Citations and bibliographies using Crossref, DataCite, PubMed and direct integration with [Zotero](https://www.zotero.org/)

-   Quarto's `.qmd` files can be edited with various code/text editors (VS Code, RStudio etc.)

::: fragment
**More reproducible as it allows others to use your underlying manuscript file in combination with your data to directly re-create your results.**
:::

## Quarto

### Presentations

Several formats: [RevealJS](https://revealjs.com/), [Microsoft Powerpoint](https://quarto.org/docs/presentations/powerpoint.html) and [Beamer](https://quarto.org/docs/presentations/beamer.html) using a common syntax.

Useful features:

-   Modern themes with functionality to publish your own theme.

-   Interactive content: Executable code blocks, graphs, maps

-   Dynamic resizing of content depending on screen size

-   Functionality for slide notes, automatic transitions, timers etc.

-   Easy export to PDF or HTML

-   Similar to manuscripts code-based content is dynamically updated.

## Quarto

### Websites

Websites to act as guides, tutorials or teaching materials:

![](assets/images/workshop_website.png){fig-align="center"}

## Quarto

### Websites

Personal websites to share publications and presentations:

![](assets/images/Personal_website.gif){fig-align="center"}

## Quarto

### Websites

Websites for research projects to share progress and results:

![](assets/images/NASCENT_website.gif){fig-align="center"}

## Quarto

### Dashboards

::: {.columns .v-center-container}
::: {.column width="60%"}
-   Arrange multiple interactive or static components in a single page with a highly customizable layout.
-   Components can include text summaries, tables, plots, maps and more.
-   Uses: Collect feedback on aspects of your research during development or present your results in a visually appealing way.
:::

::: {.column width="40%"}
![Gapminder dashboard from [JJallaire](https://jjallaire.github.io/gapminder-dashboard/)](assets/images/dashboard.gif){fig-align="center"}
:::
:::

## Quarto

### Data exploration and visualization

::: {.columns .v-center-container}
::: {.column width="50%"}

Many options for interactive data visualisations, tables and diagrams using:

-   [Plotly](https://plotly.com/python/)
-   [Leaflet](https://ipyleaflet.readthedocs.io/en/latest/)
-   [Jupyter Widgets](https://ipywidgets.readthedocs.io/en/latest/)
-   [htmlwidgets](https://www.htmlwidgets.org/)
-   [ObservableJS](https://observablehq.com/@observablehq/observables-not-javascript)
-   [Shiny](https://shiny.rstudio.com/)
:::

::: {.column width="50%"}

```{r}
#| echo: false
#| eval: true
#| output: true
#| include: true

library(leaflet)
library(fontawesome)
library(mapview)


national <- makeAwesomeIcon(text = fa("people-roof"),
                              iconColor = 'white',
                              library = 'fa',
                              markerColor = 'darkgreen')
  
regional <- makeAwesomeIcon(text = fa("people-roof"),
                              iconColor = 'white',
                              library = 'fa',
                              markerColor = 'lightgreen')


#uncomment for saving map
#Workshop_locations <- 
  leaflet(options = leafletOptions(zoomControl = FALSE,
                                 attributionControl=FALSE)) %>%
  #addProviderTiles(providers$Esri.WorldTerrain) %>%
  addTiles() %>%  # Add default OpenStreetMap map tiles
  addAwesomeMarkers(lng=-77.043,
                    lat=-12.038,
                    icon= national,
                    popup="Lima, National Workshop 9th May",
                    label = "Lima, National Workshop, 9th May",
                    labelOptions = labelOptions(#noHide = TRUE,
                                                direction = "bottom",
                                                style = list("color" = "black",
                                                "font-family" = "Roboto",
                                                "font-style" = "italic",
                                                "box-shadow" = "3px 3px rgba(0,0,0,0.25)",
                                                "font-size" = "12px",
                                                "border-color" = "rgba(0,0,0,0.5)")))%>%
  addAwesomeMarkers(lng=-69.189, lat=-12.594, icon = regional, popup="Puerto Maldonado, Regional Workshop", label = "Puerto Maldonado Regional Workshop 28th May",
                    labelOptions = labelOptions(#noHide = TRUE,
                                                direction = "bottom",
                                                style = list("color" = "black",
                                                "font-family" = "Roboto",
                                                "font-style" = "italic",
                                                "box-shadow" = "3px 3px rgba(0,0,0,0.25)",
                                                "font-size" = "12px",
                                                "border-color" = "rgba(0,0,0,0.5)")))%>%
  addAwesomeMarkers(lng=-77.529, lat=-9.526, icon = regional, popup="Huaraz, Regional Workshop", label = "Huaraz, Regional Workshop 4th June",
                    labelOptions = labelOptions(#noHide = TRUE,
                                                direction = "bottom",
                                                style = list("color" = "black",
                                                "font-family" = "Roboto",
                                                "font-style" = "italic",
                                                "box-shadow" = "3px 3px rgba(0,0,0,0.25)",
                                                "font-size" = "12px",
                                                "border-color" = "rgba(0,0,0,0.5)")))%>%
  addAwesomeMarkers(lng=-76.370, lat=-6.485, icon = regional, popup="Tarapoto, Regional Workshop", label = "Tarapoto, Regional Workshop 10th June",
                    labelOptions = labelOptions(#noHide = TRUE,
                                                direction = "bottom",
                                                style = list("color" = "black",
                                                "font-family" = "Roboto",
                                                "font-style" = "italic",
                                                "box-shadow" = "3px 3px rgba(0,0,0,0.25)",
                                                "font-size" = "12px",
                                                "border-color" = "rgba(0,0,0,0.5)")))%>%
  addAwesomeMarkers(lng=-80.63282, lat=-5.19449, icon = regional, popup="Piura, Regional Workshop", label="Piura, Regional Workshop 20th May",
                    labelOptions = labelOptions(#noHide = TRUE,
                                                direction = "bottom",
                                                style = list("color" = "black",
                                                "font-family" = "Roboto",
                                                "font-style" = "italic",
                                                "box-shadow" = "3px 3px rgba(0,0,0,0.25)",
                                                "font-size" = "12px",
                                                "border-color" = "rgba(0,0,0,0.5)")))
```

:::
:::
:::



# Let's take another 10 minute break!

# Now it's your turn!

## Guided exercises

On the website for the masterclass under the heading **Guided exercises** you will find 4 exercises that put into practice the workflows we have discussed as well as the starting to write an academic manuscript with Quarto.

-   The exercises build incrementally on each other but they don't need to be completed in order.

-   Choose which one interests you most or depending on your existing knowledge and expertise.

-   We have allocated 45 minutes to work on the exercises and we will be here to help you if you have any questions.

# Discussion and Feedback

## Discussion and Feedback

This is an open discussion so feel free to raise any points you might have, but here are some ideas: 

- Any questions of understanding or clarification about the content we have covered today?

- What are your own experiences with trying to make your work reproducible? Particular successes or obstacles you have encountered? 

- Are there any other tools or workflows that you have found useful that you would like to share with the group?

- Have you encountered any particular differences in the way that reproducibility is approached in your field/discipline?

::: notes
We have allocated 30 minutes for an open discussion and feedback
:::



# Bibliography

