{
  "hash": "777f2acd8c1846bb5da1880b78824b68",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'Reproducible Research with <img style=\"vertical-align:middle; height:1em; border: none; background: none;\" src=\"assets/images/Rlogo.png\"> and <img style=\"vertical-align:middle; height:1em;\" src=\"assets/images/quarto-logo-trademark.svg\">:\n  Workflows for projects and publications'\nsubtitle: \"A workshop presented at the [Landscape 2024 conference](https://landscape2024.org/frontend/index.php?folder_id=7393&page_id=), Berlin\"\nformat:\n  html:\n    toc: true\n    toc-title: Contents\n    toc-location: left\n    toc-depth: 2\n    number-sections: true\n    number-depth: 1\ncitation-location: margin\nlightbox: true\nexecute:\n  echo: true\n  eval: false\n  error: false\n---\n\n\n\n![](assets/images/graphical_abstract_dark.png){.lightbox width=\"70%\" fig-align=\"center\"}\n\nThis image highlights some the key concepts we will discuss in the workshop, which have been divided into seperate sections:\n\n1.    [Background](@sec-background): Some introductory information on why reproducible and transparent research is important.\n2.   [Research projects with R](@sec-Rprojects): Starting from the basics to develop good practice for creating research projects with R, focusing on some features of Rstudio as an Integrated Development Environment that can help ensure your work is reproducible.\n3.   [Workflows for reproducibility](@sec-workflows): Here we present three workflows of differing levels of complexity and discusses how they can be combined and which might be best given the research needs.\n4.   [Quarto](@sec-Quarto): Here we introduce the open-source scientific and technical publishing system Quarto which can be used for numerous academic activities including preparing manuscripts.\n5.   [Guided exercises](@sec-exercises): Now it's time to get hands-on with some guided exercises  to put into practice some of the concepts we have discussed.\n6.   [Resources](@sec-resources): A collection of resources that we find particularly helpful in our own journey towards reproducible research.\n\n# Background {#sec-background}\n\n\n\n---\neditor: \n  markdown: \n    wrap: 72\nbibliography: references.bib\n---\n\n\n<!-- Web content -->\n\n::: {.content-hidden when-format=\"revealjs\"}\n## About us\n\nWe are four researchers from the research group [Planning of Landscape\nand Urban Systems (PLUS)](https://plus.ethz.ch/) at [ETH\nZürich](https://ethz.ch/en.html). Click on the social icons below our\npictures to find out more about our individual research or get in touch\nwith us.\n\n::: {.grid style=\"display: flex; text-align: center;\"}\n::: g-col-6\n![](assets/images/Ben.jpg){.picture .lightbox}\n\n### Ben Black\n\n*Doctoral Researcher*\n\n[{{< iconify fa6-solid house-chimney-user size=xl >}}](https://blenback.github.io/){.iconify-icon}\n[{{< iconify fa6-solid envelope size=xl >}}](mailto:bblack@ethz.ch){.iconify-icon}\n[{{< iconify fa6-brands linkedin size=xl >}}](https://www.linkedin.com/in/ben-black-9889a1150/){.iconify-icon}\n[{{< iconify fa6-brands github size=xl >}}](https://github.com/blenback/){.iconify-icon}\n[{{< iconify fa6-brands researchgate size=xl >}}](https://www.researchgate.net/profile/Benjamin-Black-5/){.iconify-icon}\n:::\n\n::: g-col-6\n![](assets/images/nivedita.jpg){.picture .lightbox}\n\n### Nivedita Harisena\n\n*Doctoral Researcher*\n\n[{{< iconify fa6-solid house-chimney-user size=xl >}}](https://irl.ethz.ch/people/person-detail.Mjg5Mjgx.TGlzdC8zNzc5LC0xMzk1OTgzMDM3.html){.iconify-icon}\n[{{< iconify fa6-solid envelope size=xl >}}](mailto:nharisena@ethz.ch){.iconify-icon}\n[{{< iconify fa6-brands linkedin size=xl >}}](https://www.linkedin.com/in/nivedita-varma-harisena-667298141/){.iconify-icon}\n[{{< iconify fa6-brands github size=xl >}}](https://github.com/NVHarisena1){.iconify-icon}\n:::\n\n::: g-col-6\n![](assets/images/Manuel.jpg){.picture .lightbox}\n\n### Manuel Kurmann\n\n*Research Assistant*\n\n[{{< iconify fa6-solid house-chimney-user size=xl >}}](https://irl.ethz.ch/people/person-detail.MjM2NjYz.TGlzdC8zNzc5LC0xMzk1OTgzMDM3.html){.iconify-icon}\n[{{< iconify fa6-solid envelope size=xl >}}](mailto:mankurma@student.ethz.ch){.iconify-icon}\n[{{< iconify fa6-brands linkedin size=xl >}}](https://www.linkedin.com/in/manuel-kurmann-696577251/){.iconify-icon}\n[{{< iconify fa6-brands github size=xl >}}](https://github.com/ManuelKurmann){.iconify-icon}\n:::\n\n::: g-col-6\n![](assets/images/Maarten.jpg){.picture .lightbox}\n\n### Maarten Van Strien\n\n*Senior scientist*\n\n[{{< iconify fa6-solid house-chimney-user size=xl >}}](https://irl.ethz.ch/people/person-detail.MTYzODAz.TGlzdC8xNzM4LC0xMzk1OTgzMDM3.html){.iconify-icon}\n[{{< iconify fa6-solid envelope size=xl >}}](mailto:vanstrien@ethz.ch){.iconify-icon}\n[{{< iconify fa6-brands linkedin size=xl >}}](https://www.linkedin.com/in/maarten-van-strien-347b6747/?originalSubdomain=ch){.iconify-icon}\n[{{< iconify fa6-brands researchgate size=xl >}}](https://www.researchgate.net/profile/Maarten-Van-Strien){.iconify-icon}\n:::\n:::\n\n## What is reproducible research?\n\nReproducibility is a key aspect of reliable scientific research. It\nenables other researchers to reproduce the same results using the\noriginal data, code, and documentation [@essawy2020]. Below are the core\nprinciples to ensure reproducibility in research:\n\n**Starts with planning**\n\nReproducibility begins during the planning stage. It is essential to\norganize data management and ensure clear protocols are in place even\nbefore starting the analysis. Consistent Data Storage Regular backups of\ndata are crucial. Storing data in multiple locations ensures\naccessibility and minimizes the risk of data loss. [@alston2021]\n\n**Contains clear documentation**\n\nThorough documentation is essential to guarantee that data and methods\ncan be accurately interpreted and reproduced by others. This entails the\nuse of well-organised files and the inclusion of metadata that describes\nthe data, how it was obtained, and how it was processed.\n[@alston2021][@siraji2023]\n\n**Utilizes version control**\n\nUsing version control systems helps track changes in the project over\ntime. This approach preserves the history of the project and facilitates\nthe reversion of files to a previous state in the event of an error.\n[@alston2021]\n\n**Is accessible**\n\nData should be stored in nonproprietary, portable formats to ensure\nbroad accessibility and long-term usability. This practice ensures that\nresearchers can access the data without relying on specific software\ntools. Making data and code publicly available in accessible\nrepositories supports scientific transparency and allows broader use of\nresearch outputs. [@alston2021][@siraji2023]\n\nBy following these steps, researchers contribute to the wider scientific\ncommunity, ensuring that their work can be efficiently and accurately\nreproduced by others.\n\n## Why strive for reproducible research?\n\nIn recent years, various scientific disciplines have experienced what is\nknown as a \"replication crisis\". This crisis arises when researchers are\nunable to reproduce the headline results of key studies using the\nreported data and methods [@moonesinghe2007][@collaboration2015]\n[@bohannon2015]. This lack of reproducibility undermines public trust in\nscience, as it raises doubts about the validity of research findings.\n\n### Advantages of Reproducibility for Your Research\n\n**Personal Reference**\n\nConducting reproducible research simplifies the process of remembering\nhow and why specific analyses were performed. This makes it easier to\nexplain your work to collaborators, supervisors, and reviewers,\nenhancing communication throughout your project. [@alston2021]\n\n**Efficient**\n\nModifications Reproducible research enables you to quickly adjust\nanalyses and figures when requested by supervisors, collaborators, or\nreviewers. This streamlined process can save substantial time during\nrevisions. [@alston2021]\n\n**Streamlined Future Projects**\n\nBy maintaining well-organized and reproducible systems, you can reuse\ncode and organizational structures for future projects. This reduces the\ntime and effort required for similar tasks in subsequent research.\n[@alston2021]\n\n**Demonstrates Rigor and Transparency**\n\nReproducibility demonstrates scientific rigor and transparency. It\nallows others to verify your methods and results, improving the peer\nreview process and reducing the risk of errors or accusations of\nmisconduct. [@alston2021]\n\n**Increases Impact and Citations**\n\nMaking your research reproducible can lead to higher citation rates\n[@piwowar2007] [@mckiernan2016]. By sharing your code and data, you\nenable others to reuse your work, broadening its impact and increasing\nits relevance in the scientific community. [@whitlock2011]\n[@culina2018].\n\n### Advantages of Reproducibility for Other Researchers\n\n**Facilitates Learning**\n\nSharing data and code helps others learn from your work more easily. New\nresearchers can use your data and code as a reference, speeding up their\nlearning curve and improving the quality of their analyses.\n[@alston2021]\n\n**Enables Reproducibility**\n\nReproducible research makes it simpler for others to reproduce and build\nupon your work, fostering more compatible and robust research across\nstudies. [@alston2021]\n\n**Error Detection**\n\nBy allowing others to access and review your data and code,\nreproducibility helps detect and correct errors, ensuring that mistakes\nare caught early and reducing the chance of their propagation in future\nresearch. [@alston2021]\n\n## Why {{< iconify fa-brands r-project >}} for reproducible research?\n\nR is increasingly recognized as a powerful tool for ensuring\nreproducibility in scientific research. Here are some key advantages of\nusing R for reproducible research:\n\n**Open Source**\n\nAccessibility R is freely available to everyone, eliminating cost\nbarriers and promoting inclusive access to research tools. This\nopen-source model ensures that researchers around the world can use and\ncontribute to its development, fostering a collaborative research\nenvironment. [@siraji2023]\n\n**Comprehensive Documentation**\n\nR encourages thorough documentation of the entire research process. This\nensures that analyses are well-tracked and can be easily replicated\nacross different projects, enhancing the overall transparency and\nreliability of the research.\n\n**Integrated Version Control**\n\nR seamlessly integrates with version control systems like Git, allowing\nresearchers to track changes to code, data, and documents. This helps\nmaintain a detailed record of a project's evolution and ensures that all\nsteps are easily reproducible. [@siraji2023]\n\n**Consistency Across Platforms**\n\nR provides a stable environment that works consistently across different\noperating systems, whether you are using Windows, Mac, or Linux. This\ncross-platform consistency greatly enhances the reproducibility of\nresearch across diverse systems.\n\n**Broad Community Support**\n\nThe R community is large and active, continuously contributing to the\nimprovement of the software. This broad support makes R a reliable\nchoice for long-term research projects, ensuring that new tools and\nmethods are constantly being developed and shared.\n\n**Flexibility and Adaptability**\n\nR offers a wide range of tools and functions that can be adapted to\nvarious research needs. This flexibility allows researchers to handle\ndiverse tasks within a reproducible framework, making it a versatile\ntool for projects of all kinds.\n:::\n\n<!-- Presentation content -->\n\n::: {.content-visible when-format=\"revealjs\"}\n## About us\n\n### Ben Black\n\n::: {layout=\"[0.38, -0.02, 0.60]\" layout-valign=\"center\"}\n![](https://github.com/blenback.png){.picture .lightbox}\n\n[{{< iconify fa6-solid house-chimney-user >}}\nblenback.github.io](https://blenback.github.io/){style=\"text-decoration: none;\"}<br>\n[{{< iconify fa6-solid envelope >}}\nbblack\\@ethz.ch](mailto:bblack@ethz.ch){style=\"text-decoration: none;\"}<br>\n[{{< iconify fa6-brands linkedin >}} Ben\nBlack](https://www.linkedin.com/in/ben-black-9889a1150/){style=\"text-decoration: none;\"}<br>\n[{{< iconify fa6-brands github >}}\n\\@blenback](https://github.com/blenback/){style=\"text-decoration: none;\"}<br>\n[{{< iconify fa6-brands researchgate >}} \\Benjamin\nBlack](https://www.researchgate.net/profile/Benjamin-Black-5/){style=\"text-decoration: none;\"}<br>\n[{{< iconify simple-icons x >}}\n\\@Blen_Back](https://twitter.com/Blen_Back/){style=\"text-decoration: none;\"}<br>\n:::\n\n## About us\n\n### Nivedita Harisena\n\n## About us\n\n### Manuel Kurmann\n\n## What is reproducible research?\n\nLet's hear your thoughts: What does reproducible research mean to you?\n\n::: {.img style=\"text-align:center;\"}\n![](assets\\images\\what_is_reproducible_qr_code.png){fig-align=\"center\"}\n\n<https://www.menti.com/alsw49tprwu7>\n:::\n\n##  {background-iframe=\"https://www.mentimeter.com/app/presentation/alqogxibw u94raf69893wn32c8it8mcy/embed\"}\n\n## The FAIR standard\n\n-   **Findability, Accessibility, Interoperability, and\n    Reusability** (FAIR).\n\n-   Developed by diverse stakeholders (academia, industry, funders,\n    publishers).\n\n-   Addressed the need for infrastructure supporting data reuse.\n\n-   Emphasis on both human and machine readability.\n\n[@wilkinson2016]\n\n## Why strive for reproducible research?\n\n<!-- Use Mentimeter to take audience suggestions-->\n\n## Why strive for reproducible research?\n\n-   Replication crisis: Allows our work to be verified more thoroughly\n-   Improves science for all: Allows others to more easily build upon\n    our work\n\nDon't just take our word for it, research funders are increasingly\nfocused on reproducible research too: EXAMPLE\n\n## Why {{< iconify fa-brands r-project >}} for reproducible research?\n\n-   Open source\n-   Large active user community for support\n-   Packages to suit just about every research need: statistics,\n    modelling, spatial analysis, visualisation (Many packages developed\n    by academics)\n\nBUT just using {{< iconify fa-brands r-project >}} doesn't necessarily\nmake your research reproducible...\n\nWe have put together this workshop to share some advice for best\npractice and tips that we have picked up along the way.\n\n## Workshop concept\n\n![](assets/images/graphical_abstract_dark.png){width=\"70%\"}\n:::\n\n\n\n# Research projects with R {#sec-Rprojects}\n\n\n\n---\nbibliography: references.bib\nexecute:\n  echo: true\n  eval: false\n  error: false\n---\n\n\n<!-- Web content -->\n-------------------------------------------------------------------------------\n::: {.content-visible when-format=\"html\"}\n**Let's start with a definition of what makes a good R project from Jenny Bryan:**\n\nA good R project... *\"creates everything it needs, in its own workspace or folder, and it touches nothing it did not create.\"* [@bryan2017]\n\nThis is a good definition that contains concepts, such as the notion that projects should be 'self-contained'. However we add one more caveat to this definition which is that a good R project should *explain itself*.\n\nFor the purpose of this workshop we will approach this topic by splitting it up into 6 topics which are highlighted in this graphic:\n\n![Graphical overview of components of a good research project in R](assets/images/project_components.png)\n\nAs you move through these you will see that there are areas of overlap and complementarity between them. These topics are also central to the choice of approaches in the [three workflows for reproducibility](@sec-workflows) that we will share.\n\n## <img src=\"assets/images/RStudio_logo_flat.svg\" style=\"vertical-align:middle; height:1.5em;\"/> projects {#sec-projects}\n\nHow many times have you opened an R script and been greeted by this line:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsetwd(\"C:/Users/ben/path/that/only/I/have\")\n```\n:::\n\n\nWhile it is well-intentioned (i.e. avoiding the need to have full paths for all objects that will subsequently be loaded or daved ) the problem with it is obvious: This specific path is only relevant for the author and not other potential users and even for the author it is will be invalid if they happen to change computers. The good news is there is a very simple way to avoid having to use `setwd()` at all by using [**Rstudio Projects**]().\n\nRstudio projects designate new or existing folders as a defined working directory by creating an `.RProj` file within them. This means that when you open a project the working directory of the Rstudio session will automatically be set to the directory that the .RProj file is located in and the paths of all files in this folder will be relative to this.\n\nThe `.Rproj` file can be shared along with the rest of the research project files meaning that others users can easily open the Project to have the same working directory removing the need for those troublesome `setwd()` lines.\n\n### Creating and opening projects {#sec-creating-projects}\n\nCreating an Rstudio project is as simple as using *File \\> New Project* in the top left and then choosing between creating the Project in a new or existing directory:\n\nThere are several ways to open a Projects:\n\n1.  Using *File \\> Open Project* in the top left of Rstudio.\n\n![](assets/images/File_open_project.png){fig-align=\"center\" width=\"50%\"}\n\n2.  Using the drop down menu in the top-right of the Rstudio session.\n\n![](assets/images/Open_project_right.png){fig-align=\"center\" width=\"50%\"}\n\n3.  Outside of R by double clicking on the `.Rproj` file in the folder.\n\n![](assets/images/Open_project_explorer.png){fig-align=\"center\" width=\"50%\"}\n\n### Utilising project specific `.Rprofile`'s {#sec-rprofile}\n\nAnother useful feature of Rstudio projects is the ability to store project-specific settings using the `.Rprofile` file which controls the initialisation behaviour of the R session when the project is opened. A useful application of this for reproducible research projects is automatically open a particular script, for example a master script that runs all the code in the project (which is a concept that will discussed under [workflow decomposition](@sec-workflow-decomposition)).\n\nTo do this the contents of your `.Rprofile` file would like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsetHook(\"rstudio.sessionInit\", function(newSession) {\n  if (newSession)\n    # Open the script specificed by the path\n    rstudioapi::navigateToFile('scripts/script_to_open.R', line = -1L, column = -1L)\n}, action = \"append\")\n```\n:::\n\n\nThe easiest way to create and edit `.Rprofile` files is to use the functions from the package [`usethis`](https://usethis.r-lib.org/):\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Note the use of scope = \"project\" to create a project specific .Rprofile\nusethis::edit_r_profile(scope = \"project\")\n```\n:::\n\n\n## Environment management {#sec-environment-management}\n\nThese lines of code are also probably familiar from the beginning of many an R script:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"ggplot2\")\nlibrary(ggplot2)\n```\n:::\n\n\nBut what is wrong with these lines?\n\nWell firstly, there is no indication of what version of the package is to be installed and hence if the code installing this package is old it may not work with the most recent version of the package (This is less of a problem for well established packages like the Tidyverse but for less common packages, that may see large changes between versions, it could be substantial).\n\nSecondly, having the user install an unspecified version of a package could also cause dependency conflicts with other packages required by the code. This is because almost all packages have some form of dependency (i.e. they use the functionality of) on other packages. This is shown aptly by the image below which, while out-dated now, showed that in 2014 to install the 7 most popular R packages at the time would actually install 63 packages in total when considering their dependencies.\n\n![Package dependencies of popular R package [@devries2014]](assets/images/package_dependencies_2.png){width=\"50%\" fig-align=\"center\"}\n\nHowever the problem is bigger than just packages because when your code runs it is also utilising:\n\n-   A specific version of R\n\n-   A specific operating system\n\n-   Specific versions of system dependencies, i.e. other software in other languages that R packages themselves utilise e.g GDAL for spatial analysis packages like `terra`.\n\nAll of these things together make up what is known as the 'environment' of your code. Hence the process of documenting and managing this environment to is ensure that your code is reproducible (i.e. it not only runs but also consistently produces the same results).\n\nThere are different approaches to environment management that differ in their complexity and hence maybe suited to some projects and not others. For the purpose of this workshop we will focus on what we have found is one of the most user-friendly ways to manage your *package environment* (caveat that will be discussed) in R which is the package `renv`. Below we will introduce this package in more detail as it will form a central part of the [three workflows for reproducibility](@sec-workflows) that we present.\n\n### Creating reproducible environments with `renv`\n\nAs mentioned above [`renv`](https://rstudio.github.io/renv/articles/renv.html) is an R package that helps you create reproducible environments for your R projects by not only documenting your package environment but also providing functionality to re-create it.\n\nIt does this by creating **project specific libraries** (i.e. directories: `renv/library`) which contain all the packages used by your project. This is different from the default approach to package usage and installation whereby all packages are stored in a single library on your machine (system library). Having separate project libraries means \"that different projects can use different versions of packages and installing, updating, or removing packages in one project doesn't affect any other project.\" [@renv]. In order to make sure that your project uses the project library everytime it is opened `renv` utilises the functionality of [`.Rprofile's`](@sec-rprofile) to set the project library as the default library.\n\nAnother key process of renv is to create project specific **lockfiles** (`renv.lock`) which contain sufficient metadata about each package in the project library so that it can be re-installed on a new machine.\n\nAs alluded to, renv does a great job of managing your packages but is not intended to manage other aspects of your environment such as: tracking your version of R or your operating system. This is why if you want 'bullet-proof' reproducibility renv needs to be used alongside other approaches such as containerization which is the [3rd and most complex workflow](@sec-docker_workflow) we will discuss.\n\n## Writing clean code {#sec-writing-clean-code}\n\nThe notion of writing 'clean' code can be daunting, especially for those new to programming. However, the most important thing to bear in mind is that there is no objective measure that makes code 'clean' vs. 'un-clean', rather we should of think 'clean' coding as the pursuit of making your code easier to read, understand and maintain. Also while we should aspire to writing clean code, it is arguably more important that it functions correctly and efficiently.\n\nThe central concept of clean coding is that, like normal writing, we should follow a set of rules and conventions. For example, in English a sentence should start with a capital letter and end with a full stop. Unfortunately, in terms of writing R code there is not a single set of conventions that everyone proscribes to, instead there are numerous styles that have been outlined and the important thing is to choose a style and apply it consistently in your coding.\n\nPerhaps the two most common styles are the [Tidyverse style](https://style.tidyverse.org/) and the [Google R style](https://google.github.io/styleguide/Rguide.html) (Which is actually a derivative of the former). Neither style can be said to be the more correct, rather they express opinionated preferences on a series of common topics such as: Object naming, use of assignment operators, spacing, indentation, line length, parentheses placement, etc.\n\nRather than detail all of these topics here we will focus on just on some related tips that we think are most relevant for scientific research coding, including how to automate the formatting of your code to a particular style. However, we encourage you to go through the different style guides when you have the time.\n\n### Script headers {#sec-script_headers}\n\nStarting your scripts with a consistent header containing information about it's purpose, author/s, creation and modification dates is a great step making your workflow more understandable and hopefully reproducible. There are no rules as to what such a header should look like but this is the style I like to use:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#############################################################################\n## Script_title: Brief description of script purpose\n##\n## Notes: More detailed notes about the script and it's purpose\n##\n## Date created: \n## Author(s):\n#############################################################################\n```\n:::\n\n\nTo save time inserting this header into new scripts you use Rstudio's [**Code snippets**](https://docs.posit.co/ide/user/ide/guide/productivity/snippets.html) feature. Code snippets are simply text macros that quickly insert a section of code using a short keyword.\n\nTo create your own Code snippet go to *Tools \\> Global Options \\> Code \\> Edit Snippets* and then add a new snippet with your code below it:\n\n![](assets/images/Code_snippet_add.png){fig-align=\"center\" width=\"50%\"}\n\nTo use a code snippet simply start typing the keyword in the script and the auto-completion list will appear then press `Tab` and the code section will be inserted:\n\n![](assets/images/Code_snippet_completion.png){fig-align=\"center\" width=\"50%\"}\n\n### Code sections {#sec-code_sections}\n\nAs you may already know braced (`{}`) sections of code (i.e. function definitions, conditional blocks, etc.) can be folded to hide their contents in RStudio by clicking on the small triangle in the left margin.\n\n![](assets/images/code_section_sequential.png){fig-align=\"center\" width=\"50%\"}\n\nHowever, an often overlooked feature is the ability to create named code sections that can be also folded, as well as easily navigated between. These can be used to break longer scripts into a set of discrete regions according to specific parts of the analysis ([discussed in more detail later](@sec-workflow-decomposition)). In this regard, another good tip is to give the resulting sections sequential alphabetical or numerical Pre-fixes. Code sections are created by inserting a comment line that contains at least four trailing dashes (`-`), equal signs (`=`), or pound signs (`#`):\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Section One ---------------------------------\n \n# Section Two =================================\n \n# Section Three #############################\n```\n:::\n\n\nAlternatively you can use the *Code \\> Insert Section* command.\n\nTo navigate between code sections:\n\n-   Use the **Jump To** menu available at the bottom of the editor[@positsupport2024]\n\n![](assets/images/code_section_jumpto.png){fig-align=\"center\"}\n\n-   Use the document outline pane in the top right corner of the source pane\n\n![](assets/images/code_section_documentpane.dark.png){fig-align=\"center\"}\n\n### Automating the styling of your code\n\nThere are two R packages that are very helpful in terms of ensuring your code confirms to a consistent style: [`lintr`](https://lintr.r-lib.org/) and [`styler`](https://styler.r-lib.org/).\n\n-   `lintr` checks your code for common style issues and potential programming errors then presents them to you to correct, think of it like doing a 'spellcheck' on a written document.\n-   `styler` is more *active* in the sense that it automatically format's your code to a particular style, the default of which is the tidyverse style.\n\nTo use lintr and styler you call their functions like any package but styler can also be used through the **Rstudio Addins** menu below the Navigation bar as shown in this gif:\n\n<img src=\"https://raw.githubusercontent.com/lorenzwalthert/some_raw_data/master/styler_0.1.gif\" width=\"50%\"/>\n\nAnother very useful feature of both packages is that they can be used as part of a continuous integration (CI) workflow using a version control application like Git. This is a topic that we will cover as part of our [Version control with Git](@sec-git_workflow) workflow but what it means is that the styler and lintr functions are run automatically when you push your code to a remote repository.\n\n## Workflow decomposition {#sec-workflow-decomposition}\n\nIn computer sciences workflow decomposition refers to the structuring or compartmentalising of your code into seperate logical parts that makes it easier to maintain [@decompos2024].\n\nIn terms of coding scientific research projects many of us probably already instinctively do decomposition to some degree by splitting typical processes such as data preparation, statistical modelling, analysis of results and producing final visualizations.\n\nHowever this is not always realized in the most understandable way, for example we may have seperate scripts with logical sounding names like: `Data_prep.R` and `Data_analysis.R` but can others really be expected to know exactly which order these must be run in, or indeed whether they even need to be run sequentially at all?\n\nA good 1st step to remedying this is to give your scripts sequential numeric tags in their names, e.g. `01_Data_prep.R`, `02_Data_analysis.R`. This will also ensure that they are presented in numerical order when placed in a designated directory [Structuring your project directory](@sec-structuring) and can be explicitly described in your [project documentation](@sec-documentation).\n\nBut you can take this to the next level by creating a *Master* script that sources your other scripts in sequence (think of them as *sub-scripts*) so that users of your code need only run one script. To do this is as simple as creating the master script as you would any normal R script (*File \\> New File \\> R script*) and then using the `base::source()` function to run the sub-scripts:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#############################################################################\n## Master_script: Run steps of research project in order\n##\n## Date created: 30/7/2024\n## Author(s): Jane Doe\n#############################################################################\n\n### =========================================================================\n### A- Prepare dependent variable data\n### =========================================================================\n\n#Prepare LULC data\nsource(\"Scripts/Preparation/Dep_var_dat_prep.R\", local = scripting_env)\n\n### =========================================================================\n### B- Prepare independent variable data\n### =========================================================================\n\n#Prepare predictor data\nsource(\"Scripts/Preparation/Ind_var_data_prep.R\", local = scripting_env)\n\n### =========================================================================\n### C- Perform statisical modelling\n### =========================================================================\n\nsource(\"Scripts/Modelling/Fit_stat_models.R\", local = scripting_env)\n```\n:::\n\n\nAs you can see in this example code I have also made use of a [script header](@sec-script_headers) and [code sections](@sec-code_sections), that were previously discussed, to make the division of sub-processes even clearer. Another advantage of this approach is that all sub-scripts can utilise the same environment (defined by the `source(local= )` argument) which means that each individual script does not need to load packages or paths as objects.\n\nFinally, within your sub-scripts processes should also be seperated into code sections and ideally any repetitive tasks should be performed with custom functions which again are contained within their own files.\n\nFollowing this approach you end up with a workflow that will look something like this:\n\n![](assets/images/workflow_decomposition.png){width=\"100%\"}\n\nThe benefit of this hierarchical approach to structuring is that it is not only easier to debug and maintain individual processes but it is also more amenable to adding new processes.\n\n## Structuring your project directory {#sec-structuring}\n\nSimilar to having clean code, having a clean project directory that has well-organised sub-directories goes a long way towards making your projects code easier to understand for others. For software development there are numerous sets of conventions for directories structures although these are not always so applicable for scientific research projects. However we can borrow some basic principles, try to use: - Use logical naming - Stick to a consistent style, i.e. use of captialisation and seperators - Make use of nested sub-directories e.g `data/raw/climatic/precipitation/2020/precip_2020.rds` vs. `data/precip_2020_raw.rds`. This is very helpful when it comes to programatically constructing file paths especially in projects with a lot of data.\n\nAs an example my go-to project directory structure looks like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n└── my_project\n    ├── data # The research data\n    │   ├── raw\n    │   └── processed\n    ├── output # Storing results\n    ├── publication # Containing the academic manuscript of the project\n    ├── src # For all files that perform operations in the project\n    │   ├── scripts\n    │   └── functions\n    └── tools # Auxilliary files and settings\n```\n:::\n\n\nRather than manually create this directory structure everytime you start a new project, save yourself some time and automate it by using Rstudio's [**Project Templates**](https://docs.posit.co/ide/user/ide/guide/productivity/project-templates.html) functionality. This allows you to select a custom template as an option when creating a new [Rstudio project](@sec-creating-projects) through the New project wizard (*File \\> New Project \\> New Directory \\> New Project Template*).\n\nTo implement this even as an intermediate R user is fairly labor intensive as your custom project directory template needs to be contained within an R-package, in order to be available in the wizard. However, quite a few templates with directory structures appropriate for scientific research projects have been created by others:\n\n-   [`rrtools`](https://github.com/benmarwick/rrtools)\n\n-   [`ProjectTemplate`](http://projecttemplate.net/)\n\n-   [`template`](https://pakillo.github.io/template/)\n\n-   [`addinit`](https://dreamrs.github.io/addinit/) (Not a template but an interactive shiny add-in for project creation)\n\n## Project documentation {#sec-documentation}\n\nAs an example of why documentation is important think about if you bought a new table from Ikea only to excitedly rip open the box and find that there are no instructions for how to assemble it. Sure, you know what a table is supposedly to look like and given enough time you will end up with something that will probably be mostly right but maybe it's missing small details. Also it will probably take you just as long to take it apart in 5 years time. Well, working with undocumented code for research projects is similar except a lot more complicated!\n\nWriting comprehensive documentation that covers all aspects of our projects is time-consuming which is why it is often neglected. For example, there are a lot of different metadata conventions that exist that you could apply. However, learning and adhering strictly to these can be overwhelming and possibly lead to the opposite effect i.e. they are not simple for others to understand either.\n\nIn response to this there has been a movement in the R research community to adopt the *research as package* approach, which, as the name suggests, involves creating your project as an R-package which has a strict set of conventions for documentation [@marwick2018]. This is a viable approach for those who are familiar with R-packages but is arguably not the best for all projects and users.\n\nInstead, we would suggest to follow the maxim of *not letting the perfect be the enemy of the good* and to focus on these key areas:\n\n-   **Provide adequate in-script commentary**: This is perhaps contentious for those from a software development community, but given the choice I would rather have to read through a script with too many comments than one with too few. However remember that comments should be used to explain the purpose of the code, not what the code is doing. In line with this use [script headers](@sec-script_headers).\n\n-   **Document your functions with `roxygen` skeletons**:\n\n-   **Include a `README` file**: README files are where you should document your project at the macro-level i.e. what it is about and how it is supposed to work.\n\nThe latter of these two are more detailed so we have provided further information and tips in sections below.\n\n### Function documentation with `roxygen2` {#sec-roxygen}\n\nBase R provides a standard way of documenting a package where each function is documented in an `.Rd` file (R documentation). This documentation uses a custom syntax to detail key aspects of the functions such as their input parameters, outputs and any package dependencies [@wickham2024].\n\nIn the case of many research projects you will not be creating a package however it is still useful to apply this documentation style to your functions as it is a good way to make them understandable and easier to modify by others. For example, having clear information about the object (e.g. a vector or data.frame) that a function accepts, saves others time in guessing what the function is expecting if they are trying to use new data.\n\nHowever, rather than manually writing `.Rd` files, we can use the `roxygen2` package to automatically generate these files from a block of comments that are added to the top of the function scripts. To add this comment block, place your cursor inside a function you want to document and press `Ctrl + Shift + R` (or `Cmd + Shift + R` on Mac) or you can go to *code tools \\> insert roxygen skeleton* (code tools is represented by the wand icon in the top row of the source pane). As you can see in this gif below, when you insert the roxygen block it will already contain the names of the function names, its arguments and any returns and the function name. You can then fill in the rest of the information, such as the description and dependencies etc. for a guide to these other fields see the [roxygen2 documentation](https://roxygen2.r-lib.org/articles/rd.html).\n\n![Inserting roxygen block [@hajnala2018]](https://jozef.io/img/r102-01-add-roxy-skeleton.gif){alt=\"Inserting roxygen block\" width=\"50%\"}\n\n### Tips for README writing\n\nIf you look at the source code of R packages or projects that use R in Github repositories you will see that they all contain `README.md` files. This is the markdown format of the README file and is the most common format for README files in R projects. These files are often accompanied by the corresponding file `README.Rmd` which generates the `README.md` file. Markdown format is used for README's because it can be read by many programs and rendered in a variety of formats. In this sense writing the README for your project in markdown makes sense and there tools available to help you do this such as the `usethis` package which has a function [`use_readme_rmd()`](https://usethis.r-lib.org/reference/use_readme_rmd.html) that will create a `README.Rmd` file for you. However, depending on who you anticipate using your project you may also want to create your README as a raw text file (`.txt`) which may be a more familiar format for some users and again can be opened by many different programs.\n\nAgain there is not a single standardised format for what should be included in your README file but here is an example of a README file that was written for one of the authors code/data upload alongside a publication: [README.txt](assets/README_demo.txt)\n\nYou will see that one of the things this README includes is a tree diagram which shows the directory structure of the project right down to the file level. This is a useful way to give an overview of what users should find included in the project and then explanatory notes can be added to explain the purpose of each file or directory. Such a diagram can be easily generated using the `fs` package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"fs\")\nlibrary(fs)\n\n#vector path of the target directory to make a file tree from\nTarget_dir <- \"YOUR DIR\"\n\n#produce tree diagram of directory sub-dirs and files and save output using capture.ouput from base R utils.\ncapture.output(dir_tree(Target_dir), file= 'Dir_tree_output.txt')\n```\n:::\n\n\n:::\n\n<!-- Presentation content -->\n------------------------------------------------------------------------\n\n\n::: {.content-visible when-format=\"revealjs\"}\n**Let's start with a definition of what makes a good R project from Jenny Bryan:**\n\nA good R project... *\"creates everything it needs, in its own workspace or folder, and it touches nothing it did not create.\"* [@bryan2017]\n\nThis is a good definition that contains concepts, such as the notion that projects should be 'self-contained'. However we add one more caveat to this definition which is that a good R project should *explain itself*.\n\nFor the purpose of this workshop we will approach this topic by splitting it up into 6 topics which are highlighted in this graphic:\n\n![Graphical overview of components of a good research project in R](assets/images/project_components.png)\n\nAs you move through these you will see that there are areas of overlap and complementarity between them. These topics are also central to the choice of approaches in the [three workflows for reproducibility](@sec-workflows) that we will share.\n\n## <img src=\"assets/images/RStudio_logo_flat.svg\" style=\"vertical-align:middle; height:1.5em;\"/> projects \n\nHow many times have you opened an R script and been greeted by this line:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsetwd(\"C:/Users/ben/path/that/only/I/have\")\n```\n:::\n\n\nWhile it is well-intentioned (i.e. avoiding the need to have full paths for all objects that will subsequently be loaded or daved ) the problem with it is obvious: This specific path is only relevant for the author and not other potential users and even for the author it is will be invalid if they happen to change computers. The good news is there is a very simple way to avoid having to use `setwd()` at all by using [**Rstudio Projects**]().\n\nRstudio projects designate new or existing folders as a defined working directory by creating an `.RProj` file within them. This means that when you open a project the working directory of the Rstudio session will automatically be set to the directory that the .RProj file is located in and the paths of all files in this folder will be relative to this.\n\nThe `.Rproj` file can be shared along with the rest of the research project files meaning that others users can easily open the Project to have the same working directory removing the need for those troublesome `setwd()` lines.\n\n### Creating and opening projects {#sec-creating-projects}\n\nCreating an Rstudio project is as simple as using *File \\> New Project* in the top left and then choosing between creating the Project in a new or existing directory:\n\nThere are several ways to open a Projects:\n\n1.  Using *File \\> Open Project* in the top left of Rstudio.\n\n![](assets/images/File_open_project.png){fig-align=\"center\" width=\"50%\"}\n\n2.  Using the drop down menu in the top-right of the Rstudio session.\n\n![](assets/images/Open_project_right.png){fig-align=\"center\" width=\"50%\"}\n\n3.  Outside of R by double clicking on the `.Rproj` file in the folder.\n\n![](assets/images/Open_project_explorer.png){fig-align=\"center\" width=\"50%\"}\n\n### Utilising project specific `.Rprofile`'s {#sec-rprofile}\n\nAnother useful feature of Rstudio projects is the ability to store project-specific settings using the `.Rprofile` file which controls the initialisation behaviour of the R session when the project is opened. A useful application of this for reproducible research projects is automatically open a particular script, for example a master script that runs all the code in the project (which is a concept that will discussed under [workflow decomposition](@sec-workflow-decomposition)).\n\nTo do this the contents of your `.Rprofile` file would like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsetHook(\"rstudio.sessionInit\", function(newSession) {\n  if (newSession)\n    # Open the script specificed by the path\n    rstudioapi::navigateToFile('scripts/script_to_open.R', line = -1L, column = -1L)\n}, action = \"append\")\n```\n:::\n\n\nThe easiest way to create and edit `.Rprofile` files is to use the functions from the package [`usethis`](https://usethis.r-lib.org/):\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Note the use of scope = \"project\" to create a project specific .Rprofile\nusethis::edit_r_profile(scope = \"project\")\n```\n:::\n\n\n## Environment management \n\nThese lines of code are also probably familiar from the beginning of many an R script:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"ggplot2\")\nlibrary(ggplot2)\n```\n:::\n\n\nBut what is wrong with these lines?\n\nWell firstly, there is no indication of what version of the package is to be installed and hence if the code installing this package is old it may not work with the most recent version of the package (This is less of a problem for well established packages like the Tidyverse but for less common packages, that may see large changes between versions, it could be substantial).\n\nSecondly, having the user install an unspecified version of a package could also cause dependency conflicts with other packages required by the code. This is because almost all packages have some form of dependency (i.e. they use the functionality of) on other packages. This is shown aptly by the image below which, while out-dated now, showed that in 2014 to install the 7 most popular R packages at the time would actually install 63 packages in total when considering their dependencies.\n\n![Package dependencies of popular R package [@devries2014]](assets/images/package_dependencies_2.png){width=\"50%\" fig-align=\"center\"}\n\nHowever the problem is bigger than just packages because when your code runs it is also utilising:\n\n-   A specific version of R\n\n-   A specific operating system\n\n-   Specific versions of system dependencies, i.e. other software in other languages that R packages themselves utilise e.g GDAL for spatial analysis packages like `terra`.\n\nAll of these things together make up what is known as the 'environment' of your code. Hence the process of documenting and managing this environment to is ensure that your code is reproducible (i.e. it not only runs but also consistently produces the same results).\n\nThere are different approaches to environment management that differ in their complexity and hence maybe suited to some projects and not others. For the purpose of this workshop we will focus on what we have found is one of the most user-friendly ways to manage your *package environment* (caveat that will be discussed) in R which is the package `renv`. Below we will introduce this package in more detail as it will form a central part of the [three workflows for reproducibility](@sec-workflows) that we present.\n\n### Creating reproducible environments with `renv`\n\nAs mentioned above [`renv`](https://rstudio.github.io/renv/articles/renv.html) is an R package that helps you create reproducible environments for your R projects by not only documenting your package environment but also providing functionality to re-create it.\n\nIt does this by creating **project specific libraries** (i.e. directories: `renv/library`) which contain all the packages used by your project. This is different from the default approach to package usage and installation whereby all packages are stored in a single library on your machine (system library). Having separate project libraries means \"that different projects can use different versions of packages and installing, updating, or removing packages in one project doesn't affect any other project.\" [@renv]. In order to make sure that your project uses the project library everytime it is opened `renv` utilises the functionality of [`.Rprofile's`](@sec-rprofile) to set the project library as the default library.\n\nAnother key process of renv is to create project specific **lockfiles** (`renv.lock`) which contain sufficient metadata about each package in the project library so that it can be re-installed on a new machine.\n\nAs alluded to, renv does a great job of managing your packages but is not intended to manage other aspects of your environment such as: tracking your version of R or your operating system. This is why if you want 'bullet-proof' reproducibility renv needs to be used alongside other approaches such as containerization which is the [3rd and most complex workflow](@sec-docker_workflow) we will discuss.\n\n## Writing clean code \n\nThe notion of writing 'clean' code can be daunting, especially for those new to programming. However, the most important thing to bear in mind is that there is no objective measure that makes code 'clean' vs. 'un-clean', rather we should of think 'clean' coding as the pursuit of making your code easier to read, understand and maintain. Also while we should aspire to writing clean code, it is arguably more important that it functions correctly and efficiently.\n\nThe central concept of clean coding is that, like normal writing, we should follow a set of rules and conventions. For example, in English a sentence should start with a capital letter and end with a full stop. Unfortunately, in terms of writing R code there is not a single set of conventions that everyone proscribes to, instead there are numerous styles that have been outlined and the important thing is to choose a style and apply it consistently in your coding.\n\nPerhaps the two most common styles are the [Tidyverse style](https://style.tidyverse.org/) and the [Google R style](https://google.github.io/styleguide/Rguide.html) (Which is actually a derivative of the former). Neither style can be said to be the more correct, rather they express opinionated preferences on a series of common topics such as: Object naming, use of assignment operators, spacing, indentation, line length, parentheses placement, etc.\n\nRather than detail all of these topics here we will focus on just on some related tips that we think are most relevant for scientific research coding, including how to automate the formatting of your code to a particular style. However, we encourage you to go through the different style guides when you have the time.\n\n### Script headers {#sec-script_headers}\n\nStarting your scripts with a consistent header containing information about it's purpose, author/s, creation and modification dates is a great step making your workflow more understandable and hopefully reproducible. There are no rules as to what such a header should look like but this is the style I like to use:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#############################################################################\n## Script_title: Brief description of script purpose\n##\n## Notes: More detailed notes about the script and it's purpose\n##\n## Date created: \n## Author(s):\n#############################################################################\n```\n:::\n\n\nTo save time inserting this header into new scripts you use Rstudio's [**Code snippets**](https://docs.posit.co/ide/user/ide/guide/productivity/snippets.html) feature. Code snippets are simply text macros that quickly insert a section of code using a short keyword.\n\nTo create your own Code snippet go to *Tools \\> Global Options \\> Code \\> Edit Snippets* and then add a new snippet with your code below it:\n\n![](assets/images/Code_snippet_add.png){fig-align=\"center\" width=\"50%\"}\n\nTo use a code snippet simply start typing the keyword in the script and the auto-completion list will appear then press `Tab` and the code section will be inserted:\n\n![](assets/images/Code_snippet_completion.png){fig-align=\"center\" width=\"50%\"}\n\n### Code sections {#sec-code_sections}\n\nAs you may already know braced (`{}`) sections of code (i.e. function definitions, conditional blocks, etc.) can be folded to hide their contents in RStudio by clicking on the small triangle in the left margin.\n\n![](assets/images/code_section_sequential.png){fig-align=\"center\" width=\"50%\"}\n\nHowever, an often overlooked feature is the ability to create named code sections that can be also folded, as well as easily navigated between. These can be used to break longer scripts into a set of discrete regions according to specific parts of the analysis ([discussed in more detail later](@sec-workflow-decomposition)). In this regard, another good tip is to give the resulting sections sequential alphabetical or numerical Pre-fixes. Code sections are created by inserting a comment line that contains at least four trailing dashes (`-`), equal signs (`=`), or pound signs (`#`):\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Section One ---------------------------------\n \n# Section Two =================================\n \n# Section Three #############################\n```\n:::\n\n\nAlternatively you can use the *Code \\> Insert Section* command.\n\nTo navigate between code sections:\n\n-   Use the **Jump To** menu available at the bottom of the editor[@positsupport2024]\n\n![](assets/images/code_section_jumpto.png){fig-align=\"center\"}\n\n-   Use the document outline pane in the top right corner of the source pane\n\n![](assets/images/code_section_documentpane.dark.png){fig-align=\"center\"}\n\n### Automating the styling of your code\n\nThere are two R packages that are very helpful in terms of ensuring your code confirms to a consistent style: [`lintr`](https://lintr.r-lib.org/) and [`styler`](https://styler.r-lib.org/).\n\n-   `lintr` checks your code for common style issues and potential programming errors then presents them to you to correct, think of it like doing a 'spellcheck' on a written document.\n-   `styler` is more *active* in the sense that it automatically format's your code to a particular style, the default of which is the tidyverse style.\n\nTo use lintr and styler you call their functions like any package but styler can also be used through the **Rstudio Addins** menu below the Navigation bar as shown in this gif:\n\n<img src=\"https://raw.githubusercontent.com/lorenzwalthert/some_raw_data/master/styler_0.1.gif\" width=\"50%\"/>\n\nAnother very useful feature of both packages is that they can be used as part of a continuous integration (CI) workflow using a version control application like Git. This is a topic that we will cover as part of our [Version control with Git](@sec-git_workflow) workflow but what it means is that the styler and lintr functions are run automatically when you push your code to a remote repository.\n\n## Workflow decomposition \n\nIn computer sciences workflow decomposition refers to the structuring or compartmentalising of your code into seperate logical parts that makes it easier to maintain [@decompos2024].\n\nIn terms of coding scientific research projects many of us probably already instinctively do decomposition to some degree by splitting typical processes such as data preparation, statistical modelling, analysis of results and producing final visualizations.\n\nHowever this is not always realized in the most understandable way, for example we may have seperate scripts with logical sounding names like: `Data_prep.R` and `Data_analysis.R` but can others really be expected to know exactly which order these must be run in, or indeed whether they even need to be run sequentially at all?\n\nA good 1st step to remedying this is to give your scripts sequential numeric tags in their names, e.g. `01_Data_prep.R`, `02_Data_analysis.R`. This will also ensure that they are presented in numerical order when placed in a designated directory [Structuring your project directory](@sec-structuring) and can be explicitly described in your [project documentation](@sec-documentation).\n\nBut you can take this to the next level by creating a *Master* script that sources your other scripts in sequence (think of them as *sub-scripts*) so that users of your code need only run one script. To do this is as simple as creating the master script as you would any normal R script (*File \\> New File \\> R script*) and then using the `base::source()` function to run the sub-scripts:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#############################################################################\n## Master_script: Run steps of research project in order\n##\n## Date created: 30/7/2024\n## Author(s): Jane Doe\n#############################################################################\n\n### =========================================================================\n### A- Prepare dependent variable data\n### =========================================================================\n\n#Prepare LULC data\nsource(\"Scripts/Preparation/Dep_var_dat_prep.R\", local = scripting_env)\n\n### =========================================================================\n### B- Prepare independent variable data\n### =========================================================================\n\n#Prepare predictor data\nsource(\"Scripts/Preparation/Ind_var_data_prep.R\", local = scripting_env)\n\n### =========================================================================\n### C- Perform statisical modelling\n### =========================================================================\n\nsource(\"Scripts/Modelling/Fit_stat_models.R\", local = scripting_env)\n```\n:::\n\n\nAs you can see in this example code I have also made use of a [script header](@sec-script_headers) and [code sections](@sec-code_sections), that were previously discussed, to make the division of sub-processes even clearer. Another advantage of this approach is that all sub-scripts can utilise the same environment (defined by the `source(local= )` argument) which means that each individual script does not need to load packages or paths as objects.\n\nFinally, within your sub-scripts processes should also be seperated into code sections and ideally any repetitive tasks should be performed with custom functions which again are contained within their own files.\n\nFollowing this approach you end up with a workflow that will look something like this:\n\n![](assets/images/workflow_decomposition.png){width=\"100%\"}\n\nThe benefit of this hierarchical approach to structuring is that it is not only easier to debug and maintain individual processes but it is also more amenable to adding new processes.\n\n## Structuring your project directory \n\nSimilar to having clean code, having a clean project directory that has well-organised sub-directories goes a long way towards making your projects code easier to understand for others. For software development there are numerous sets of conventions for directories structures although these are not always so applicable for scientific research projects. However we can borrow some basic principles, try to use: - Use logical naming - Stick to a consistent style, i.e. use of captialisation and seperators - Make use of nested sub-directories e.g `data/raw/climatic/precipitation/2020/precip_2020.rds` vs. `data/precip_2020_raw.rds`. This is very helpful when it comes to programatically constructing file paths especially in projects with a lot of data.\n\nAs an example my go-to project directory structure looks like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n└── my_project\n    ├── data # The research data\n    │   ├── raw\n    │   └── processed\n    ├── output # Storing results\n    ├── publication # Containing the academic manuscript of the project\n    ├── src # For all files that perform operations in the project\n    │   ├── scripts\n    │   └── functions\n    └── tools # Auxilliary files and settings\n```\n:::\n\n\nRather than manually create this directory structure everytime you start a new project, save yourself some time and automate it by using Rstudio's [**Project Templates**](https://docs.posit.co/ide/user/ide/guide/productivity/project-templates.html) functionality. This allows you to select a custom template as an option when creating a new [Rstudio project](@sec-creating-projects) through the New project wizard (*File \\> New Project \\> New Directory \\> New Project Template*).\n\nTo implement this even as an intermediate R user is fairly labor intensive as your custom project directory template needs to be contained within an R-package, in order to be available in the wizard. However, quite a few templates with directory structures appropriate for scientific research projects have been created by others:\n\n-   [`rrtools`](https://github.com/benmarwick/rrtools)\n\n-   [`ProjectTemplate`](http://projecttemplate.net/)\n\n-   [`template`](https://pakillo.github.io/template/)\n\n-   [`addinit`](https://dreamrs.github.io/addinit/) (Not a template but an interactive shiny add-in for project creation)\n\n## Project documentation \n\nAs an example of why documentation is important think about if you bought a new table from Ikea only to excitedly rip open the box and find that there are no instructions for how to assemble it. Sure, you know what a table is supposedly to look like and given enough time you will end up with something that will probably be mostly right but maybe it's missing small details. Also it will probably take you just as long to take it apart in 5 years time. Well, working with undocumented code for research projects is similar except a lot more complicated!\n\nWriting comprehensive documentation that covers all aspects of our projects is time-consuming which is why it is often neglected. For example, there are a lot of different metadata conventions that exist that you could apply. However, learning and adhering strictly to these can be overwhelming and possibly lead to the opposite effect i.e. they are not simple for others to understand either.\n\nIn response to this there has been a movement in the R research community to adopt the *research as package* approach, which, as the name suggests, involves creating your project as an R-package which has a strict set of conventions for documentation [@marwick2018]. This is a viable approach for those who are familiar with R-packages but is arguably not the best for all projects and users.\n\nInstead, we would suggest to follow the maxim of *not letting the perfect be the enemy of the good* and to focus on these key areas:\n\n-   **Provide adequate in-script commentary**: This is perhaps contentious for those from a software development community, but given the choice I would rather have to read through a script with too many comments than one with too few. However remember that comments should be used to explain the purpose of the code, not what the code is doing. In line with this use [script headers](@sec-script_headers).\n\n-   **Document your functions with `roxygen` skeletons**:\n\n-   **Include a `README` file**: README files are where you should document your project at the macro-level i.e. what it is about and how it is supposed to work.\n\nThe latter of these two are more detailed so we have provided further information and tips in sections below.\n\n### Function documentation with `roxygen2` {#sec-roxygen}\n\nBase R provides a standard way of documenting a package where each function is documented in an `.Rd` file (R documentation). This documentation uses a custom syntax to detail key aspects of the functions such as their input parameters, outputs and any package dependencies [@wickham2024].\n\nIn the case of many research projects you will not be creating a package however it is still useful to apply this documentation style to your functions as it is a good way to make them understandable and easier to modify by others. For example, having clear information about the object (e.g. a vector or data.frame) that a function accepts, saves others time in guessing what the function is expecting if they are trying to use new data.\n\nHowever, rather than manually writing `.Rd` files, we can use the `roxygen2` package to automatically generate these files from a block of comments that are added to the top of the function scripts. To add this comment block, place your cursor inside a function you want to document and press `Ctrl + Shift + R` (or `Cmd + Shift + R` on Mac) or you can go to *code tools \\> insert roxygen skeleton* (code tools is represented by the wand icon in the top row of the source pane). As you can see in this gif below, when you insert the roxygen block it will already contain the names of the function names, its arguments and any returns and the function name. You can then fill in the rest of the information, such as the description and dependencies etc. for a guide to these other fields see the [roxygen2 documentation](https://roxygen2.r-lib.org/articles/rd.html).\n\n![Inserting roxygen block [@hajnala2018]](https://jozef.io/img/r102-01-add-roxy-skeleton.gif){alt=\"Inserting roxygen block\" width=\"50%\"}\n\n### Tips for README writing\n\nIf you look at the source code of R packages or projects that use R in Github repositories you will see that they all contain `README.md` files. This is the markdown format of the README file and is the most common format for README files in R projects. These files are often accompanied by the corresponding file `README.Rmd` which generates the `README.md` file. Markdown format is used for README's because it can be read by many programs and rendered in a variety of formats. In this sense writing the README for your project in markdown makes sense and there tools available to help you do this such as the `usethis` package which has a function [`use_readme_rmd()`](https://usethis.r-lib.org/reference/use_readme_rmd.html) that will create a `README.Rmd` file for you. However, depending on who you anticipate using your project you may also want to create your README as a raw text file (`.txt`) which may be a more familiar format for some users and again can be opened by many different programs.\n\nAgain there is not a single standardised format for what should be included in your README file but here is an example of a README file that was written for one of the authors code/data upload alongside a publication: [README.txt](assets/README_demo.txt)\n\nYou will see that one of the things this README includes is a tree diagram which shows the directory structure of the project right down to the file level. This is a useful way to give an overview of what users should find included in the project and then explanatory notes can be added to explain the purpose of each file or directory. Such a diagram can be easily generated using the `fs` package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"fs\")\nlibrary(fs)\n\n#vector path of the target directory to make a file tree from\nTarget_dir <- \"YOUR DIR\"\n\n#produce tree diagram of directory sub-dirs and files and save output using capture.ouput from base R utils.\ncapture.output(dir_tree(Target_dir), file= 'Dir_tree_output.txt')\n```\n:::\n\n:::\n------------------------------------------------------------------------------\n\n\n\n# Workflows for Reproducibility {#sec-workflows}\n\nFor this workshop we will outline three different workflows for creating reproducible research projects with R combined with other tools. We have named these workflows as follows:\n1. Rstudio project to Zenodo pipeline\n2. Containerization with Docker\n3. Version control with Git\n\nThese workflows are inter-related in the sense that 2. and 3. build upon elements of the first and indeed the techniques of the latter workflows can also be combined together. The workflows differ in the level of reproducibility they ensure but the trade-off for better reproducibility is increased complexity. As such we would suggest that the most reproducible workflow may not always be the most appropriate to implement dependent on the needs of your research project and the capabilities of the collaborators involved.\n\n** TO DO?: Add a table to compare the workflows **\n\nOf course, these workflows are by no-means the only way of doing things and indeed we would actively encourage you to expand upon them in developing your own preferred approach.  \n\n## Rstudio project to Zenodo pipeline {#sec-zenodo_workflow}\n\n![](assets/images/project_zenodo_workflow.png){.lightbox width=\"70%\" fig-align=\"center\"}\n\n\n---\nexecute:\n  echo: true\n  eval: false\n  error: false\neditor: \n  markdown: \n    wrap: 72\nbibliography: references.bib\n---\n\n\n<!-- Web content -->\n\n::: {.content-hidden when-format=\"revealjs\"}\n### Environment Management with renv\n\nrenv is a powerful R package designed to help manage project\nenvironments by creating project-specific libraries and lockfiles. As\nmentioned earlier, renv captures the exact versions of R packages used\nin a project, storing this information in a renv.lock file. This allows\nusers to recreate the exact package environment when revisiting a\nproject or transferring it to a different machine, ensuring\nreproducibility.\n\nThe renv workflow is straightforward:\n\n-   Initialize renv in a project: renv creates a separate library in the\n    project folder, isolating the packages from the system-wide library.\n\n-   Snapshot dependencies: renv scans the project, identifying which\n    packages are being used and recording their versions in the\n    lockfile.\n\n-   Restore environments: Anyone cloning or receiving the project can\n    run renv::restore() to install the exact versions of the packages\n    listed in the lockfile, reproducing the original project\n    environment.\n\nOne of the core strengths of renv is its flexibility. It integrates\nseamlessly with tools like RStudio, allowing easy management of\ndependencies without disrupting existing workflows. This makes it\nparticularly well-suited for ensuring that research projects are\nreproducible across different systems and platforms.\n\nHowever, renv does not manage the **entire system environment** (such as\nthe version of R itself or external dependencies like system libraries).\nFor complete reproducibility, combining renv with containerization tools\n(like Docker) or publishing outputs (such as code or data) via\nrepositories like Zenodo is recommended. The use of renv allows\nresearchers to easily capture and restore the R environment, while\nrepositories can ensure the long-term availability of the project’s\noutputs.\n\nThe code specific workflow is straightforward and well explained in the\ndocumentation: <https://rstudio.github.io/renv/articles/renv.html>\n\n### Publishing and Archiving with Zenodo\n\nZenodo complements renv by providing a platform to publish, archive, and\nshare research outputs, including datasets, code, and publications.\nCreated by CERN and OpenAIRE, Zenodo ensures that research artifacts are\naccessible for the long term, aligning with open science principles.\nEach item published on Zenodo is assigned a permanent DOI, making it\neasy to reference and cite in academic work.\n\nA unique feature of Zenodo is its support for versioning. Researchers\ncan update their work over time, while earlier versions remain\naccessible, ensuring transparency and reproducibility. This versioning\nsystem is crucial in scientific research, where updated analyses and\ndata corrections are often necessary, but reproducibility of original\nwork must be maintained.\n\nThe zen4R package [@blondel2024] enhances the integration of R with\nZenodo by providing tools to programmatically interact with Zenodo’s API\ndirectly from R. This package allows researchers to:\n\n-   Upload datasets and code to Zenodo.\n\n-   Automate the publication process by creating new records, updating\n    metadata, and managing depositions.\n\n-   Retrieve information about existing Zenodo records.\n\nThis makes it easier to publish research outputs, ensuring that\nversioning, DOIs, and metadata management are handled efficiently within\nR workflows, facilitating reproducibility and sharing in open science\npractices. Learn more about the zen4R package:\n<https://cran.r-project.org/web/packages/zen4R/vignettes/zen4R.html>\n\nZenodo also integrates seamlessly with GitHub. When a research project\n(e.g., code) is hosted on GitHub, Zenodo can automatically archive the\nrepository upon each new release, creating a snapshot with a DOI. This\nintegration simplifies the process of ensuring that research code is\npreserved in an immutable form, contributing to better practices in\nreproducible science. \n\nWhile renv focuses on internal reproducibility by controlling the R\nenvironment, Zenodo ensures external reproducibility by providing a\nstable and citable repository for the research outputs. Combining both\ntools allows researchers to capture the environment in which their\nanalysis was conducted and share it along with their data and code.\nTogether, renv and Zenodo form a comprehensive solution for\nreproducible, open science research in accordance with the FAIR guiding\nprinciples [@wilkinson2016].\n:::\n\n<!-- Presentation content -->\n\n::: {.content-visible when-format=\"revealjs\"}\n### Managing Project Environments with renv\n\n-   renv creates project-specific libraries\n\n-   Captures package versions in a renv.lock file\n\n-   Ensures reproducibility across machines\n\n-   Centralizes environment management within each project\n\n::: {.notes}\n-   renv helps manage R package environments by creating isolated\n    libraries specific to each project, ensuring that the project uses\n    only the packages it needs.\n\n-   The renv.lock file records exact versions of all installed packages,\n    allowing consistent reproducibility.\n\n-   This feature is especially useful for transferring projects between\n    machines, maintaining a controlled environment.\n\n-   It centralizes the environment management within the project folder,\n    avoiding conflicts with global R libraries.\n:::\n\n### renv Workflow\n\n-   Initialize renv to isolate project dependencies\n\n-   Snapshot dependencies to create a lockfile\n\n-   Restore environments using renv::restore()\n\n-   Easy integration with RStudio for workflow management\n\n::: {.notes}\n-   Initialize renv in a project to isolate packages from the\n    system-wide library.\n\n-   Snapshot the project’s package dependencies, generating a lockfile\n    (renv.lock).\n\n-   Restore the environment by reinstalling packages using the lockfile.\n\n-   renv integrates smoothly with RStudio, making it easy to use\n    alongside other development tools.\n:::\n\n### Limitations of renv\n\n-   Does not manage R versions or external dependencies\n\n-   Focuses on internal reproducibility\n\n-   Best combined with containerization (e.g., Docker)\n\n-   Complements external repositories (e.g., Zenodo)\n\n::: {.notes}\n-   renv does not manage system-wide components like the R version or\n    external libraries.\n\n-   renv ensures internal reproducibility.\n\n-   For full reproducibility, renv should be combined with tools like\n    Docker for system environment control.\n\n-   Publishing platforms like Zenodo can be used to store code and data\n    for long-term preservation.\n:::\n\n### Publishing and Archiving with Zenodo\n\n-   Provides long-term storage for research outputs\n\n-   Assigns permanent DOIs for citations\n\n-   Supports versioning for transparency\n\n-   Simplifies archiving from GitHub with DOI snapshots\n\n::: {.notes}\n-   Zenodo provides a repository for long-term archiving of datasets,\n    code, and publications, ensuring accessibility.\n\n-   Each uploaded item is assigned a permanent DOI for easy citation in\n    research.\n\n-   Zenodo’s versioning feature allows researchers to update projects\n    while keeping previous versions accessible.\n\n-   Integration with GitHub allows automatic archiving of new code\n    releases, creating DOI-linked snapshots.\n:::\n\n### Enhancing Workflow with zen4R\n\n-   Upload datasets, code, and metadata from R to Zenodo\n\n-   Automate publication and deposition management\n\n-   Retrieve and update Zenodo records directly in R\n\n-   Facilitates integration and reproducibility in R workflows\n\n::: {.notes}\n-   zen4R allows R users to interact with Zenodo’s API to upload data\n    and code directly from R.\n\n-   It supports automated publication, including metadata management and\n    record updating.\n\n-   Retrieve and update Zenodo records programmatically within R.\n\n-   This makes publishing more efficient, especially in workflows\n    requiring frequent updates or version control.\n:::\n\n### Combining renv and Zenodo\n\n-   RENV manages internal project environments\n\n-   Zenodo ensures external reproducibility with archiving\n\n-   Together, they provide a comprehensive solution\n\n-   Aligns with open science and FAIR principles \n\n::: {.notes}\n-   RENV manages internal environments by locking package versions and\n    dependencies.\n\n-   Zenodo provides external storage and ensures reproducibility by\n    archiving and versioning research outputs.\n\n-   Together, they create a comprehensive solution for reproducible,\n    open science projects.\n\n-   This combination aligns with FAIR principles, ensuring data is\n    Findable, Accessible, Interoperable, and Reusable.\n:::\n\n:::\n\n\n\n## Containerisation with Docker{#sec-docker_workflow}\n\n\n\n---\nbibliography: references.bib\nexecute:\n  echo: true\n  eval: false\n  error: false\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n<!-- Web content -->\n\n::: {.content-visible when-format=\"html\"}\n![](assets/images/Docker_workflow.png){.lightbox width=\"70%\"\nfig-align=\"center\"}\n\n**The title of this workflow raises two questions, the first being: what\nis containerization?**\n\nSimply put containerization is the process of bundling code along with\nall of it's dependencies, i.e. all the components we discussed as making\nup the [environment](@sec-environment-management), including the\noperating system, software libraries (packages), and other system\nsoftware. The fact everything needed to run the code is included means\nthat the code is portable and can be run on any platform or cloud\nservice. This also makes containerization something of a gold standard\nfor reproducibility as the entire environment is explicitly re-produced.\n\n**and the second: what is Docker?**\n\n[Docker](https://www.docker.com/) is an open-source, and the most\npopular, platform for containerization. Before we dive into a practical\nexample using Docker for research projects with R it is important to\nintroduce some three key terms that we will come across:\n\n-   `Dockerfile`: The first step in the containerization process, they\n    are a straightforward text file containing a collection of commands\n    or procedures to create a new Docker Image. In this sense we can\n    consider a Dockerfile are the source code of Docker Image.\n    Importantly, Dockerfiles typically start from a base image, which is\n    a existing Docker Image that your image is extending.\n\n-   `Docker Image`: A read-only file that contains the instructions for\n    creating a Docker Container. Think of an image as the blueprint of\n    what will be in a container when it is running. Docker Images can be\n    shared via [Dockerhub](https://hub.docker.com/), so that they can be\n    used by others.\n\n-   `Docker Container`: Is an actual running instance of a Docker image.\n    It runs completely isolated from the host environment by default and\n    only accesses host files (i.e. data) if it has been configured to do\n    so. It is possible to create multiple containers simultaneously from\n    the same Docker Image, and each container can be started, stopped,\n    moved, and deleted independently of the others.\n\nThe graphic below show the relationships between these components\nincluding the central commands of Docker that connect them `build` and\n`run`:\n\n![](assets/images/docker_explainer.png){.lightbox width=\"70%\"\nfig-align=\"center\"}\n\n### Using Docker with R\n\nSo to create a `Docker Image` to containerize our R research projects we\nneed to start by creating a `Dockerfile` and, as mentioned above, this should\nstart with a base image. In our case this base image must logically\ninclude R and RStudio (if we want to utilise the RStudio Projects\nfeatures).\n\nFortunately there is a project that specifically catalogs and manages\nDocker Images for R projects: [`Rocker`](https://rocker-project.org/).\nThe images available through the Rocker project not only include\ndifferent versions of R and RStudio but also images containing\ncollections of R packages for specific purposes (e.g. tidyverse for data\nwrangling and visualisation, geospatial packages etc.).\n\nIn terms of actually creating the `Dockerfile` for our R project, this\ncan be done manually (See a good R-focused tutorial[here](https://colinfay.me/docker-r-reproducibility/)), however there are also R packages that can help with this process such as [`dockerfiler`](https://thinkr-open.github.io/dockerfiler/) and the `[rrtools`](https://github.com/benmarwick/rrtools) package. \n\nFor our workflow we will use the `dockerfiler` package.\n- Main function of the package is `dockerfile_build()` which creates a Dockerfile and builds a Docker image from it.\n\n\n\n### Docker with renv\n\n### Creating docker image \n\n### Running docker container\n\n\n\n\n\n\n\n\n\nhttps://github.com/noamross/nyhackr-docker-talk/blob/master/Noam_Ross_DockerForTheUseR_nyhackr_2018-07-10.pdf\n\nhttps://www.statworx.com/en/content-hub/blog/running-your-r-script-in-docker/\n\nstevedore package for pulling images from Dockerhub using the Docker API\nhttps://richfitz.github.io/stevedore/\n:::\n\n\n\n## Version control with Git{#sec-git_workflow}\n\n![](assets/images/version_control_workflow.png){.lightbox width=\"70%\" fig-align=\"center\"}\n<!--{{< include contents/Git_workflow.qmd >}}-->\n\n# Quarto {#sec-Quarto}\n\n\n<!-- Web content -->\n:::: {.content-hidden when-format=\"revealjs\"}\n## A brief introduction to Quarto\n\nQuatro is a unified authoring framework that allows for the integration of code, written material and a wide variety of interactive visual formats into one publishable finished document.\n\n####  Quarto allows you to:\n\n-   Create dynamic content that is updated as your code changes\n\n-   Numerous thematic settings for high quality formatting including 'Pandoc' markdown support for equations and cross-referencing\n\n-   Publish your work as websites or books\n\n-   Edit with any text editor including VS Code, RStudio and more\n\n### Some of the creative ways in which you can use Quarto is:\n\n#### 1. Visualize and publish interactive plots using html widgets\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(plotly)\np <- ggplot(data = diamonds, aes(x = cut, fill = clarity)) +\n            geom_bar(position = \"dodge\")\nggplotly(p)\n```\n:::\n\n\n\n#### 2. Create interactive geo-spatial mapping segments\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(leaflet)\n\nleaflet() %>%\n  addTiles() %>%  # Add default OpenStreetMap map tiles\n  addMarkers(lng= 8.548, lat=47.376, popup=\"ETH\")\n```\n:::\n\n\n#### 3. Create multi-purpose dashboards to demostrate your research output\n\n\n![](https://quarto.org/docs/dashboards/examples/thumbnails/customer-churn-dashboard.png){width=60% fig-align=\"center\"}\n:::\n\n<!-- Presentation content -->\n::: {.content-visible when-format=\"revealjs\"}\n\n\n\n:::\n\n\n\n\n# Guided excercises {#sec-exercises}\n\n\n\n---\nexecute:\n  echo: true\n  eval: false\n  error: false\n---\n\n\n\n## Rstudio project to Zenodo exercise {#sec-Rproj_zenodo_exercise}\n\n\n\n\n\n---\nexecute:\n  echo: true\n  eval: false\n  error: false\n---\n\n\n## Containerisation with Docker exercise\n\nIn this exercise we will create a Docker container for a simple R project. The project is the same that is created in the first workflow [exercise](@sec-Rproj_zenodo_exercise), however to save time or in case you haven't completed this exercise we will start with the finished output from it.  \n\n<br><a href=\"https://www.example.com/example.zip\" class=\"download\"><i class=\"fa fa-download\"></i> <b>Download Source Code Files</b></a>\n\n\n\n---\ntitle: \"Untitled\"\neditor: visual\n---\n\n\n\n\n## Write a paper with Quarto\n\n\n\n\n# Resources {#sec-resources}\n\n<!--{{\\< include contents/resources.qmd \\>}}-->\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}