{
  "hash": "a733ba7a749bd884071abc41dc6e505c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Using renv with Docker\"\noutput: rmarkdown::html_vignette\nvignette: >\n  %\\VignetteIndexEntry{Using renv with Docker}\n  %\\VignetteEngine{knitr::rmarkdown}\n  %\\VignetteEncoding{UTF-8}\n---\n\n\n\n\n\n\n\nWhile renv can help capture the state of your R library at some point in time, there are still other aspects of the system that can influence the run-time behavior of your R application.\nIn particular, the same R code can produce different results depending on:\n\n-   The operating system in use,\n-   The compiler flags used when R and packages are built,\n-   The LAPACK / BLAS system(s) in use,\n-   The versions of system libraries installed and in use,\n\nAnd so on.\n[Docker](https://www.docker.com/) is a tool that helps solve this problem through the use of **containers**.\nVery roughly speaking, one can think of a container as a small, self-contained system within which different applications can be run.\nUsing Docker, one can declaratively state how a container should be built (what operating system it should use, and what system software should be installed within), and use that system to run applications.\n(For more details, please see <https://environments.rstudio.com/docker>.)\n\nUsing Docker and renv together, one can then ensure that both the underlying system, alongside the required R packages, are fixed and constant for a particular application.\n\nThe main challenges in using Docker with renv are:\n\n-   Ensuring that the renv cache is visible to Docker containers, and\n\n-   Ensuring that required R package dependencies are available at run-time.\n\nThis vignette will assume you are already familiar with Docker; if you are not yet familiar with Docker, the [Docker Documentation](https://docs.docker.com/) provides a thorough introduction.\nTo learn more about using Docker to manage R environments, visit [environments.rstudio.com](https://environments.rstudio.com/docker.html).\n\nWe'll discuss two strategies for using renv with Docker:\n\n1.  Using renv to install packages when the Docker image is generated;\n2.  Using renv to install packages when Docker containers are run.\n\nWe'll also explore the pros and cons of each strategy.\n\n## Creating Docker images with renv\n\nWith Docker, [Dockerfiles](https://docs.docker.com/engine/reference/builder/) are used to define new images.\nDockerfiles can be used to declaratively specify how a Docker image should be created.\nA Docker image captures the state of a machine at some point in time -- e.g., a Linux operating system after downloading and installing R 4.3.\nDocker containers can be created using that image as a base, allowing different independent applications to run using the same pre-defined machine state.\n\nFirst, you'll need to get renv installed on your Docker image.\nThe easiest way to accomplish this is with the `remotes` package.\nFor example, you could install the latest release of `renv` from CRAN:\n\n```\nRUN R -e \"install.packages('renv', repos = c(CRAN = 'https://cloud.r-project.org'))\"\n```\n\nAlternatively, if you needed to use the development version of `renv`, you could use:\n\n```         \nRUN R -e \"install.packages('remotes', repos = c(CRAN = 'https://cloud.r-project.org'))\"\nRUN R -e \"remotes::install_github('rstudio/renv')\"\n```\n\nNext, if you'd like the `renv.lock` lockfile to be used to install R packages when the Docker image is built, you'll need to copy it to the container:\n\n```         \nWORKDIR /project\nCOPY renv.lock renv.lock\n```\n\nNext, you need to tell renv which library paths to use for package installation.\nYou can either set the `RENV_PATHS_LIBRARY` environment variable to a writable path within your Docker container, or copy the renv auto-loader tools into the container so that a project-local library can be automatically provisioned and used when R is launched.\n\n```         \n# approach one\nENV RENV_PATHS_LIBRARY renv/library\n\n# approach two\nRUN mkdir -p renv\nCOPY .Rprofile .Rprofile\nCOPY renv/activate.R renv/activate.R\nCOPY renv/settings.json renv/settings.json\n```\n\nFinally, you can run `renv::restore()` to restore packages as defined in the lockfile:\n\n```         \nRUN R -e \"renv::restore()\"\n```\n\nWith this, renv will download and install the requisite packages as appropriate when the image is created.\nAny new containers created from this image will hence have those R packages installed and visible at run-time.\n\n## Speeding up package installations\n\nThe aforementioned approach is useful if you have multiple applications with\nidentical package requirements. In this case, a single image containing this\nidentical package library could serve as the parent image for several \ncontainerized applications.\n\nHowever, `renv::restore()` is slow -- it needs to download and install packages, \nwhich can take some time. Thus, some care is required to efficiently make use\nof the `renv` cache for projects that require: \n\n1. Building an image multiple times (e.g., to debug the production application\n   as source code is updated), or\n\n2. Calling `renv::restore()` each time the container is run.\n\nThe former process can be sped up using multi-stage builds, the latter by dynamically provisioning R Libraries, as described below.\n\n### Multi-stage builds\n\nFor projects that require repeatedly building an image, \n[multi-stage builds](https://docs.docker.com/build/building/multi-stage/) \ncan be used to speed up the build process. With multi-stage builds, multiple \nFROM statements are used in the Dockerfile and files can be copied across \nbuild stages. \n\nThis approach can be leveraged to generate more efficient builds\nby dedicating a first stage build to package synchronization and a second stage\nbuild to copying files and executing code that may need to be updated often \nacross builds (e.g., code that needs to be debugged in the container).\n\nTo implement a two stage build, the following code could be used as part of a\nDockerfile.\n\n```\n# STAGE 1: renv-related code\nFROM <parent_image> AS base\n\nWORKDIR /project\n\n# using approach 2 above\nRUN mkdir -p renv\nCOPY renv.lock renv.lock\nCOPY .Rprofile .Rprofile\nCOPY renv/activate.R renv/activate.R\nCOPY renv/settings.dcf renv/settings.dcf\n\n# change default location of cache to project folder\nRUN mkdir renv/.cache\nENV RENV_PATHS_CACHE renv/.cache\n\n# restore \nRUN R -e \"renv::restore()\"\n```\n\nThe above code uses `FROM <parent_image> AS <name>` to name the first stage of \nthe build `base`. Here, `<parent_image>` should be replaced with an appropriate \nimage name. \n\nSubsequently, the code uses approach 2 (described above) to copy the auto-loader\nto the project directory in the image. It additionally creates the `renv/.cache`\ndirectory that is to be used as the `renv` cache.\n\nThe second stage of the build is defined by adding the following code to the \nsame Dockerfile, below the previous code chunk.\n\n```\nFROM <parent_image>\n\nWORKDIR /project\nCOPY --from=base /project .\n\n# add commands that need to be debugged below\n```\n\nHere, `<parent_image>` could be the same as the parent image of `base`, but does \nnot have to be (see \n[documentation](https://docs.docker.com/build/building/multi-stage/) for more \ndetails).\n\nThe key line is the `COPY` command, which specifies that the contents of \n`/project` directory from the `base` image are copied into the `/project` \ndirectory of this image. \n\nAny commands that will change frequently across builds could be included below\nthe `COPY` command. If only this code associated with the second stage \nbuild is updated then `renv::restore()` will not be called again at build time.\nInstead, the layers associated with the `base` image will be loaded from \nDocker's cache, thereby saving significant time in build process.\n\nIn fact, `renv::restore()` will only be called when the `base` image needs to be \nrebuilt (e.g., when changes are made to `renv.lock`). Docker's cache system is\ngenerally good at understanding the dependencies of images. However, if you find\nthat the `base` image is not updating as expected, it is possible to manually \nenforce a clean build by including the `--no-cache` option in the call to \n`docker build`.\n\n### Dynamically Provisioning R Libraries with renv\n\nHowever, on occasion, one will have multiple applications built from a single base image, but each application will have its own independent R package requirements.\nIn this case, rather than including the package dependencies in the image itself, it would be preferable for each container to provision its own library at run-time, based on that application's `renv.lock` lockfile.\n\nIn effect, this is as simple as ensuring that `renv::restore()` happens at container run-time, rather than image build time.\nHowever, on its own, `renv::restore()` is slow -- it needs to download and install packages, which could take prohibitively long if an application needs to be run repeatedly.\n\nThe renv package cache can be used to help ameliorate this issue.\nWhen the cache is enabled, whenever renv attempts to install or restore an R package, it first checks to see whether that package is already available within the renv cache.\nIf it is, that instance of the package is linked into the project library.\nOtherwise, the package is first installed into the renv cache, and then that newly-installed copy is linked for use in the project.\n\nIn effect, if the renv cache is available, you should only need to pay the cost of package installation once -- after that, the newly-installed package will be available for re-use across different projects.\nAt the same time, each project's library will remain independent and isolated from one another, so installing a package within one container won't affect another container.\n\nHowever, by default, each Docker container will have its own independent filesystem.\nIdeally, we'd like for *all* containers launched from a particular image to have access to the same renv cache.\nTo accomplish this, we'll have to tell each container to use an renv cache located on a shared mount.\n\nIn sum, if we'd like to allow for run-time provisioning of R package dependencies, we will need to ensure the renv cache is located on a shared volume, which is visible to any containers launched.\nWe will accomplish this by:\n\n1.  Setting the `RENV_PATHS_CACHE` environment variable, to tell the instance of renv running in each container where the global cache lives;\n\n2.  Telling Docker to mount some filesystem location from the host filesystem, at some location (`RENV_PATHS_CACHE_HOST`), to a container-specific location (`RENV_PATHS_CACHE_CONTAINER`).\n\nFor example, if you had a container running a Shiny application:\n\n```         \n# the location of the renv cache on the host machine\nRENV_PATHS_CACHE_HOST=/opt/local/renv/cache\n\n# where the cache should be mounted in the container\nRENV_PATHS_CACHE_CONTAINER=/renv/cache\n\n# run the container with the host cache mounted in the container\ndocker run --rm \\\n    -e \"RENV_PATHS_CACHE=${RENV_PATHS_CACHE_CONTAINER}\" \\\n    -v \"${RENV_PATHS_CACHE_HOST}:${RENV_PATHS_CACHE_CONTAINER}\" \\\n    -p 14618:14618 \\\n    R -s -e 'renv::restore(); shiny::runApp(host = \"0.0.0.0\", port = 14618)'\n```\n\nWith this, any calls to renv APIs within the created docker container will have access to the mounted cache.\nThe first time you run a container, renv will likely need to populate the cache, and so some time will be spent downloading and installing the required packages.\nSubsequent runs will be much faster, as renv will be able to reuse the global package cache.\n\nThe primary downside with this approach compared to the image-based approach is that it requires you to modify how containers are created, and requires a bit of extra orchestration in how containers are launched.\nHowever, once the renv cache is active, newly-created containers will launch very quickly, and a single image can then be used as a base for a myriad of different containers and applications, each with their own independent package dependencies.\n\n## Handling the renv autoloader\n\nWhen `R` is launched within a project folder, the renv auto-loader (if present) will attempt to download and install renv into the project library.\nDepending on how your Docker container is configured, this could fail.\nFor example:\n\n```         \nError installing renv:\n======================\nERROR: unable to create '/usr/local/pipe/renv/library/master/R-4.0/x86_64-pc-linux-gnu/renv'\nWarning messages:\n1: In system2(r, args, stdout = TRUE, stderr = TRUE) :\n  running command ''/usr/lib/R/bin/R' --vanilla CMD INSTALL -l 'renv/library/master/R-4.0/x86_64-pc-linux-gnu' '/tmp/RtmpwM7ooh/renv_0.12.2.tar.gz' 2>&1' had status 1\n2: Failed to find an renv installation: the project will not be loaded.\nUse `renv::activate()` to re-initialize the project.\n```\n\nBootstrapping renv into the project library might be unnecessary for you.\nIf that is the case, then you can avoid this behavior by launching R with the `--vanilla` flag set; for example:\n\n```         \nR --vanilla -s -e 'renv::restore()'\n```\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}